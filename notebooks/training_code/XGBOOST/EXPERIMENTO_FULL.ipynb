{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "import os\n",
    "\n",
    "new_directory = r'c://Users//Fer//TESIS_ARCHIVOS//TESIS_AIRE//MP_Forecasting//aqi_forecasting//notebooks'\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "import numpy as np # for data manipulation\n",
    "\n",
    "\n",
    "# Training utils\n",
    "from training_code.utils import utils_xgboost\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Tiempo\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta, MO\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression # for building a linear regression model\n",
    "from sklearn.svm import SVR # for building SVR model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import mean_absolute_error #MAE\n",
    "from sklearn.metrics import mean_absolute_percentage_error #MAPE\n",
    "from sklearn.metrics import mean_squared_error #MSE, para RMSE: squared = False\n",
    "\n",
    "# Visualizations\n",
    "import plotly.graph_objects as go # for data visualization\n",
    "import plotly.express as px # for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('datos/230127_train_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "validacion = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study_5_0.25_2 done!\n",
      "study_5_0.5_2 done!\n",
      "study_5_1_2 done!\n",
      "study_5_0.25_7 done!\n",
      "study_5_0.5_7 done!\n",
      "study_5_1_7 done!\n",
      "study_5_0.25_15 done!\n",
      "study_5_0.5_15 done!\n",
      "study_5_1_15 done!\n",
      "study_30_0.25_2 done!\n",
      "study_30_0.5_2 done!\n",
      "study_30_1_2 done!\n",
      "study_30_0.25_7 done!\n",
      "study_30_0.5_7 done!\n",
      "study_30_1_7 done!\n",
      "study_30_0.25_15 done!\n",
      "study_30_0.5_15 done!\n",
      "study_30_1_15 done!\n",
      "study_60_0.25_2 done!\n",
      "study_60_0.5_2 done!\n",
      "study_60_1_2 done!\n",
      "study_60_0.25_7 done!\n",
      "study_60_0.5_7 done!\n",
      "study_60_1_7 done!\n",
      "study_60_0.25_15 done!\n",
      "study_60_0.5_15 done!\n",
      "study_60_1_15 done!\n"
     ]
    }
   ],
   "source": [
    "horizon = [0.25, 0.5, 1]\n",
    "resample = [5, 30, 60]\n",
    "previous = [2, 7, 15]\n",
    "\n",
    "# Start resampling\n",
    "\n",
    "for resample_item in resample:\n",
    "\n",
    "    df_test = validacion.copy()\n",
    "    df_train = datos.copy()\n",
    "\n",
    "    df_test.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train = df_train.set_index('FECHAHORA', drop = True)\n",
    "    df_test = df_test.set_index('FECHAHORA', drop = True)\n",
    "\n",
    "    lista_resample = []\n",
    "\n",
    "    if resample_item != 5: \n",
    "\n",
    "        r_i = str(resample_item) + 'T'\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_train[df_train['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_train = pd.concat(lista_resample)\n",
    "\n",
    "        lista_resample = []\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_test[df_test['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_test = pd.concat(lista_resample)\n",
    "\n",
    "    df_test['ANHO'] = df_test.index.year\n",
    "    df_test['MES'] = df_test.index.month\n",
    "    df_test['DIA'] = df_test.index.day\n",
    "    df_test['HORA'] = df_test.index.hour\n",
    "    df_test['MINUTO'] = df_test.index.minute\n",
    "    df_test['FECHAHORA'] = df_test.index\n",
    "    df_test.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    df_train['ANHO'] = df_train.index.year\n",
    "    df_train['MES'] = df_train.index.month\n",
    "    df_train['HORA'] = df_train.index.hour\n",
    "    df_train['MINUTO'] = df_train.index.minute\n",
    "    df_train['DIA'] = df_train.index.day\n",
    "    df_train['FECHAHORA'] = df_train.index\n",
    "    df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    df_test.to_csv('datos/experimento_full/test_resample_'+str(resample_item)+'_minutes.csv')\n",
    "    df_train.to_csv('datos/experimento_full/train_resample_'+str(resample_item)+'_minutes.csv')\n",
    "\n",
    "    # OPTUNA\n",
    "\n",
    "    for previous_item in previous:\n",
    "        for horizon_item in horizon:\n",
    "            \n",
    "            estacion = 4\n",
    "\n",
    "            variables = [\"ANHO\", 'DIA', 'MES', 'HORA', 'MINUTO', 'MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5', 'TIPO', 'TRAFICO', 'HUMEDAD', \n",
    "                        'PRESION', 'TEMPERATURA','DIA_SEM']\n",
    "\n",
    "            dependent = ['AQI_MP2_5']\n",
    "\n",
    "            number_of_features = len(variables)\n",
    "\n",
    "            training_days = previous_item\n",
    "            forecast_days = horizon_item\n",
    "\n",
    "            if resample_item == 5:\n",
    "                samples_per_day = 288\n",
    "            elif resample_item == 30:\n",
    "                samples_per_day = 48\n",
    "            elif resample_item == 60:\n",
    "                samples_per_day = 24\n",
    "\n",
    "            step = forecast_days*samples_per_day\n",
    "\n",
    "            train_months = relativedelta(months = 12)\n",
    "\n",
    "            input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "            output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "            train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "            X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                                estacion,\n",
    "                                                                train_months, \n",
    "                                                                variables, \n",
    "                                                                dependent, \n",
    "                                                                train_test_samples, \n",
    "                                                                input_samples, \n",
    "                                                                output_samples, \n",
    "                                                                number_of_features,\n",
    "                                                                step)\n",
    "\n",
    "            def objective(trial):\n",
    "    \n",
    "                params = {\n",
    "                    'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "                    'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 10, 300),\n",
    "                    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                    'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
    "                    'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "                    'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "                }\n",
    "                \n",
    "                optuna_xgb_model = xgb.XGBRegressor(** params)\n",
    "                \n",
    "                trained_xgb_model = MultiOutputRegressor(optuna_xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_test)\n",
    "                print('MAPE: ', MAPE)\n",
    "                MAE = np.mean(np.abs(prediction - y_test))\n",
    "                print('MAE: ', MAE)\n",
    "\n",
    "                MSE = mean_squared_error(prediction, y_test)\n",
    "                \n",
    "                return MSE\n",
    "\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "\n",
    "            study.optimize(objective, n_trials = 100 )\n",
    "\n",
    "            trial = study.best_trial\n",
    "\n",
    "            joblib.dump(study, \"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "            # VALIDATION\n",
    "\n",
    "            study = joblib.load(\"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "            params = study.best_params\n",
    "\n",
    "            predicciones = {}\n",
    "            metricas = {}\n",
    "            \n",
    "            for i in range(1,11):\n",
    "\n",
    "                estacion = i\n",
    "\n",
    "                X_train_val, y_train_val = utils_xgboost.get_validation(df_test, \n",
    "                                                                        estacion,\n",
    "                                                                        variables, \n",
    "                                                                        dependent, \n",
    "                                                                        train_test_samples, \n",
    "                                                                        input_samples, \n",
    "                                                                        output_samples, \n",
    "                                                                        number_of_features,\n",
    "                                                                        step)\n",
    "                xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "                trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                prediction = trained_xgb_model.predict(X_train_val)\n",
    "                \n",
    "                # guardamos los valores predecidos vs reales en un diccionario\n",
    "                \n",
    "                predicciones[i] = {'real' : y_train_val, 'prediccion': prediction}\n",
    "\n",
    "\n",
    "                pickle.dump(trained_xgb_model, open('models/models_xgboost/experimento_full/xgboost_estacion_' + str(i) + '_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.pkl', 'wb'))\n",
    "\n",
    "                mean_real = y_train_val.mean()\n",
    "                mean_prediction = prediction.mean()\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_train_val)\n",
    "                MAE = mean_absolute_error(prediction, y_train_val)\n",
    "                RMSE = mean_squared_error(prediction, y_train_val, squared = False)\n",
    "                \n",
    "                # guardamos las metricas en un diccionario\n",
    "                \n",
    "                metricas[i] = {'MAE': MAE, \"MAPE\": MAPE, 'RMSE': RMSE, 'Media real' : mean_real, 'Media predecida': mean_prediction}\n",
    "\n",
    "            df_metricas = pd.DataFrame.from_dict(metricas)\n",
    "\n",
    "            df_metricas.to_csv('metrics/XGBOOST/experimento_full/xgboost_experimento_full_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "            list_dfs = []\n",
    "\n",
    "            for station in range(1,11):\n",
    "                d = {'TARGET': predicciones[station]['real'].flatten(), 'FORECAST': predicciones[station]['prediccion'].flatten()}\n",
    "                df_aux = pd.DataFrame(data = d)\n",
    "                df_aux['ESTACION'] = station\n",
    "                list_dfs.append(df_aux)\n",
    "\n",
    "            df_predicciones = pd.concat(list_dfs)\n",
    "\n",
    "            df_predicciones.to_csv('datos/experimento_full/predicciones_10estaciones_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "            print('study_'+ str(resample_item)+'_'+str(horizon_item)+'_'+ str(previous_item)+' done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRÁFICAS - 6 HORAS DE PREDICCIÓN - MEJORES RESULTADOS\n",
    "\n",
    "* Resample = 5 minutos\n",
    "* Mirando atras 2, 7 y 15 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacion = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "dias_2 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.5_previous_2.csv')\n",
    "dias_7 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.5_previous_7.csv')\n",
    "dias_15 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.5_previous_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221760 entries, 0 to 221759\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  221760 non-null  int64  \n",
      " 1   TARGET      221760 non-null  float64\n",
      " 2   FORECAST    221760 non-null  float64\n",
      " 3   ESTACION    221760 non-null  int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "#validacion.info() # 264960\n",
    "#dias_2.info() # 259200\n",
    "#dias_7.info() # 244800\n",
    "dias_15.info() # 221760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221760 entries, 0 to 221759\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   level_0           221760 non-null  int64  \n",
      " 1   index             221760 non-null  int64  \n",
      " 2   Unnamed: 0        221760 non-null  int64  \n",
      " 3   TARGET            221760 non-null  float64\n",
      " 4   FORECAST_2_ATRAS  221760 non-null  float64\n",
      " 5   ESTACION          221760 non-null  int64  \n",
      " 6   indice            221760 non-null  int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 11.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221760 entries, 0 to 221759\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   ESTACION                221760 non-null  int64         \n",
      " 1   FECHAHORA               221760 non-null  datetime64[ns]\n",
      " 2   ANHO                    221760 non-null  int64         \n",
      " 3   DIA                     221760 non-null  int64         \n",
      " 4   MES                     221760 non-null  int64         \n",
      " 5   HORA                    221760 non-null  int64         \n",
      " 6   MINUTO                  221760 non-null  int64         \n",
      " 7   MP1                     221760 non-null  float64       \n",
      " 8   MP2_5                   221760 non-null  float64       \n",
      " 9   MP10                    221760 non-null  float64       \n",
      " 10  TEMPERATURA             221760 non-null  float64       \n",
      " 11  HUMEDAD                 221760 non-null  float64       \n",
      " 12  PRESION                 221760 non-null  float64       \n",
      " 13  DIA_TRAF_COD            221760 non-null  object        \n",
      " 14  TRAFICO_COD             221760 non-null  object        \n",
      " 15  TRAFICO                 221760 non-null  int64         \n",
      " 16  TIPO_COD                221760 non-null  object        \n",
      " 17  TIPO                    221760 non-null  int64         \n",
      " 18  DIA_SEM                 221760 non-null  int64         \n",
      " 19  AQI_MP2_5               221760 non-null  float64       \n",
      " 20  AQI_MP10                221760 non-null  float64       \n",
      " 21  MEDICION_DIA            221760 non-null  int64         \n",
      " 22  MP1_ANTERIOR            221760 non-null  float64       \n",
      " 23  MP2_5_ANTERIOR          221760 non-null  float64       \n",
      " 24  MP10_ANTERIOR           221760 non-null  float64       \n",
      " 25  TEMPERATURA_PRONOSTICO  221760 non-null  float64       \n",
      " 26  HUMEDAD_PRONOSTICO      221760 non-null  float64       \n",
      " 27  PRESION_PRONOSTICO      221760 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(10), object(3)\n",
      "memory usage: 47.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORECAST_15_ATRAS</th>\n",
       "      <th>FORECAST_7_ATRAS</th>\n",
       "      <th>FORECAST_2_ATRAS</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>FECHAHORA</th>\n",
       "      <th>ANHO</th>\n",
       "      <th>DIA</th>\n",
       "      <th>MES</th>\n",
       "      <th>HORA</th>\n",
       "      <th>MINUTO</th>\n",
       "      <th>...</th>\n",
       "      <th>DIA_SEM</th>\n",
       "      <th>AQI_MP2_5</th>\n",
       "      <th>AQI_MP10</th>\n",
       "      <th>MEDICION_DIA</th>\n",
       "      <th>MP1_ANTERIOR</th>\n",
       "      <th>MP2_5_ANTERIOR</th>\n",
       "      <th>MP10_ANTERIOR</th>\n",
       "      <th>TEMPERATURA_PRONOSTICO</th>\n",
       "      <th>HUMEDAD_PRONOSTICO</th>\n",
       "      <th>PRESION_PRONOSTICO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.916775</td>\n",
       "      <td>24.746069</td>\n",
       "      <td>23.980480</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:05:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.449</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2.269</td>\n",
       "      <td>30.7</td>\n",
       "      <td>83.9</td>\n",
       "      <td>997.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.855766</td>\n",
       "      <td>24.773897</td>\n",
       "      <td>24.085901</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:10:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>159</td>\n",
       "      <td>1.549</td>\n",
       "      <td>2.089</td>\n",
       "      <td>2.460</td>\n",
       "      <td>30.4</td>\n",
       "      <td>84.5</td>\n",
       "      <td>997.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.655935</td>\n",
       "      <td>24.527283</td>\n",
       "      <td>23.993942</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:15:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1.379</td>\n",
       "      <td>2.089</td>\n",
       "      <td>3.259</td>\n",
       "      <td>30.4</td>\n",
       "      <td>85.7</td>\n",
       "      <td>997.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.762094</td>\n",
       "      <td>24.896280</td>\n",
       "      <td>23.874578</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:20:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>161</td>\n",
       "      <td>1.309</td>\n",
       "      <td>1.849</td>\n",
       "      <td>12.979</td>\n",
       "      <td>30.2</td>\n",
       "      <td>85.9</td>\n",
       "      <td>997.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.627117</td>\n",
       "      <td>24.736176</td>\n",
       "      <td>24.159529</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:25:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>162</td>\n",
       "      <td>1.079</td>\n",
       "      <td>1.529</td>\n",
       "      <td>1.630</td>\n",
       "      <td>30.6</td>\n",
       "      <td>83.8</td>\n",
       "      <td>997.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FORECAST_15_ATRAS  FORECAST_7_ATRAS  FORECAST_2_ATRAS  ESTACION  \\\n",
       "0          24.916775         24.746069         23.980480         1   \n",
       "1          24.855766         24.773897         24.085901         1   \n",
       "2          24.655935         24.527283         23.993942         1   \n",
       "3          24.762094         24.896280         23.874578         1   \n",
       "4          24.627117         24.736176         24.159529         1   \n",
       "\n",
       "            FECHAHORA  ANHO  DIA  MES  HORA  MINUTO  ...  DIA_SEM  AQI_MP2_5  \\\n",
       "0 2021-04-14 13:05:00  2021   14    4    13       5  ...        2       25.0   \n",
       "1 2021-04-14 13:10:00  2021   14    4    13      10  ...        2       25.0   \n",
       "2 2021-04-14 13:15:00  2021   14    4    13      15  ...        2       25.0   \n",
       "3 2021-04-14 13:20:00  2021   14    4    13      20  ...        2       29.0   \n",
       "4 2021-04-14 13:25:00  2021   14    4    13      25  ...        2       29.0   \n",
       "\n",
       "   AQI_MP10  MEDICION_DIA  MP1_ANTERIOR  MP2_5_ANTERIOR MP10_ANTERIOR  \\\n",
       "0       7.0           158         1.449           2.039         2.269   \n",
       "1       7.0           159         1.549           2.089         2.460   \n",
       "2       7.0           160         1.379           2.089         3.259   \n",
       "3       7.0           161         1.309           1.849        12.979   \n",
       "4       7.0           162         1.079           1.529         1.630   \n",
       "\n",
       "  TEMPERATURA_PRONOSTICO  HUMEDAD_PRONOSTICO PRESION_PRONOSTICO  \n",
       "0                   30.7                83.9              997.8  \n",
       "1                   30.4                84.5              997.8  \n",
       "2                   30.4                85.7              997.6  \n",
       "3                   30.2                85.9              997.6  \n",
       "4                   30.6                83.8              997.6  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validacion = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "dias_2 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.5_previous_2.csv')\n",
    "dias_7 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.5_previous_7.csv')\n",
    "dias_15 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.5_previous_15.csv')\n",
    "\n",
    "dias_2.rename(columns={'FORECAST': 'FORECAST_2_ATRAS'}, inplace = True)\n",
    "dias_7.rename(columns={'FORECAST': 'FORECAST_7_ATRAS'}, inplace = True)\n",
    "dias_15.rename(columns={'FORECAST': 'FORECAST_15_ATRAS'}, inplace = True)\n",
    "\n",
    "lista_2 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = dias_2[dias_2['ESTACION'] == i]\n",
    "\n",
    "    df_aux.reset_index(inplace = True)\n",
    "\n",
    "    df_aux['indice'] = df_aux.index\n",
    "\n",
    "    #print(df_aux.info())\n",
    "\n",
    "    df_aux_2 = df_aux[df_aux['indice'] > 3743]\n",
    "\n",
    "    #print(df_aux_2.info())\n",
    "\n",
    "    lista_2.append(df_aux_2)\n",
    "\n",
    "dias_2_c = pd.concat(lista_2)\n",
    "dias_2_c.reset_index(inplace = True)\n",
    "\n",
    "print(dias_2_c.info())\n",
    "\n",
    "lista_7 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = dias_7[dias_7['ESTACION'] == i]\n",
    "    \n",
    "    df_aux.reset_index(inplace = True)\n",
    "\n",
    "    df_aux['indice'] = df_aux.index\n",
    "\n",
    "    df_aux_7 = df_aux[df_aux['indice'] > 2303]\n",
    "\n",
    "    lista_7.append(df_aux_7)\n",
    "\n",
    "dias_7_c = pd.concat(lista_7)\n",
    "dias_7_c.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "dias_15.reset_index(inplace = True)\n",
    "\n",
    "lista = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = validacion[validacion['ESTACION'] == i]\n",
    "\n",
    "    first_pred = df_aux.FECHAHORA.min() + relativedelta(days=15)\n",
    "\n",
    "    df_aux = df_aux[df_aux['FECHAHORA'] >= first_pred]\n",
    "\n",
    "    lista.append(df_aux)\n",
    "\n",
    "df = pd.concat(lista)\n",
    "\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "df_2_c = dias_2_c.FORECAST_2_ATRAS\n",
    "df_7_c = dias_7_c.FORECAST_7_ATRAS\n",
    "df_15 = dias_15.FORECAST_15_ATRAS\n",
    "\n",
    "df = pd.merge(df_2_c, df, right_index = True, left_index=True)\n",
    "df = pd.merge(df_7_c, df, right_index = True,  left_index=True)\n",
    "df = pd.merge(df_15, df, right_index=True, left_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "\n",
    "    fig_val = go.Figure()\n",
    "\n",
    "    df_grafica = df[df['ESTACION'] == i]\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.AQI_MP2_5), x = list(df_grafica.FECHAHORA), name = 'AQI Real'))\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_2_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 2 días atrás'))\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_7_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 7 días atrás'))\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_15_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 15 días atrás'))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=\"Title\",\n",
    "        xaxis=dict(\n",
    "            title=\"X Label\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Y label\"\n",
    "        ) ) \n",
    "\n",
    "    fig_val.update_layout( \n",
    "                            title={\n",
    "                                'text': \"Estación \" + str(i) + \". AQI real vs Predicciones a 6 horas\",\n",
    "                                'y':0.9,\n",
    "                                'x':0.5,\n",
    "                                'xanchor': 'center',\n",
    "                                'yanchor': 'top'}, \n",
    "                        yaxis_title = 'AQI MP2.5', \n",
    "                        xaxis_title = 'Fecha',\n",
    "                        legend_title = 'Referencias',\n",
    "                            font=dict(\n",
    "                                    size=16,\n",
    "                                        ),\n",
    "                        )\n",
    "\n",
    "    fig_val.write_html('graphs/XGBOOST/experimento_full/estacion_'+str(i)+'_AQI_vs_prediccion_6hs_2dias_7dias_15dias_resample5min.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICAS - 12 HORAS DE PREDICCION - MEJORES RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221760 entries, 0 to 221759\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   level_0           221760 non-null  int64  \n",
      " 1   index             221760 non-null  int64  \n",
      " 2   Unnamed: 0        221760 non-null  int64  \n",
      " 3   TARGET            221760 non-null  float64\n",
      " 4   FORECAST_2_ATRAS  221760 non-null  float64\n",
      " 5   ESTACION          221760 non-null  int64  \n",
      " 6   indice            221760 non-null  int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 11.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221760 entries, 0 to 221759\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   ESTACION                221760 non-null  int64         \n",
      " 1   FECHAHORA               221760 non-null  datetime64[ns]\n",
      " 2   ANHO                    221760 non-null  int64         \n",
      " 3   DIA                     221760 non-null  int64         \n",
      " 4   MES                     221760 non-null  int64         \n",
      " 5   HORA                    221760 non-null  int64         \n",
      " 6   MINUTO                  221760 non-null  int64         \n",
      " 7   MP1                     221760 non-null  float64       \n",
      " 8   MP2_5                   221760 non-null  float64       \n",
      " 9   MP10                    221760 non-null  float64       \n",
      " 10  TEMPERATURA             221760 non-null  float64       \n",
      " 11  HUMEDAD                 221760 non-null  float64       \n",
      " 12  PRESION                 221760 non-null  float64       \n",
      " 13  DIA_TRAF_COD            221760 non-null  object        \n",
      " 14  TRAFICO_COD             221760 non-null  object        \n",
      " 15  TRAFICO                 221760 non-null  int64         \n",
      " 16  TIPO_COD                221760 non-null  object        \n",
      " 17  TIPO                    221760 non-null  int64         \n",
      " 18  DIA_SEM                 221760 non-null  int64         \n",
      " 19  AQI_MP2_5               221760 non-null  float64       \n",
      " 20  AQI_MP10                221760 non-null  float64       \n",
      " 21  MEDICION_DIA            221760 non-null  int64         \n",
      " 22  MP1_ANTERIOR            221760 non-null  float64       \n",
      " 23  MP2_5_ANTERIOR          221760 non-null  float64       \n",
      " 24  MP10_ANTERIOR           221760 non-null  float64       \n",
      " 25  TEMPERATURA_PRONOSTICO  221760 non-null  float64       \n",
      " 26  HUMEDAD_PRONOSTICO      221760 non-null  float64       \n",
      " 27  PRESION_PRONOSTICO      221760 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(10), object(3)\n",
      "memory usage: 47.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORECAST_15_ATRAS</th>\n",
       "      <th>FORECAST_7_ATRAS</th>\n",
       "      <th>FORECAST_2_ATRAS</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>FECHAHORA</th>\n",
       "      <th>ANHO</th>\n",
       "      <th>DIA</th>\n",
       "      <th>MES</th>\n",
       "      <th>HORA</th>\n",
       "      <th>MINUTO</th>\n",
       "      <th>...</th>\n",
       "      <th>DIA_SEM</th>\n",
       "      <th>AQI_MP2_5</th>\n",
       "      <th>AQI_MP10</th>\n",
       "      <th>MEDICION_DIA</th>\n",
       "      <th>MP1_ANTERIOR</th>\n",
       "      <th>MP2_5_ANTERIOR</th>\n",
       "      <th>MP10_ANTERIOR</th>\n",
       "      <th>TEMPERATURA_PRONOSTICO</th>\n",
       "      <th>HUMEDAD_PRONOSTICO</th>\n",
       "      <th>PRESION_PRONOSTICO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.104820</td>\n",
       "      <td>25.031105</td>\n",
       "      <td>24.801626</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:05:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.449</td>\n",
       "      <td>2.039</td>\n",
       "      <td>2.269</td>\n",
       "      <td>30.7</td>\n",
       "      <td>83.9</td>\n",
       "      <td>997.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.997310</td>\n",
       "      <td>24.936530</td>\n",
       "      <td>24.801247</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:10:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>159</td>\n",
       "      <td>1.549</td>\n",
       "      <td>2.089</td>\n",
       "      <td>2.460</td>\n",
       "      <td>30.4</td>\n",
       "      <td>84.5</td>\n",
       "      <td>997.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.977419</td>\n",
       "      <td>24.728025</td>\n",
       "      <td>24.718630</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:15:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1.379</td>\n",
       "      <td>2.089</td>\n",
       "      <td>3.259</td>\n",
       "      <td>30.4</td>\n",
       "      <td>85.7</td>\n",
       "      <td>997.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.919670</td>\n",
       "      <td>25.325490</td>\n",
       "      <td>24.706661</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:20:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>161</td>\n",
       "      <td>1.309</td>\n",
       "      <td>1.849</td>\n",
       "      <td>12.979</td>\n",
       "      <td>30.2</td>\n",
       "      <td>85.9</td>\n",
       "      <td>997.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.971413</td>\n",
       "      <td>25.105440</td>\n",
       "      <td>24.691515</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-14 13:25:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>162</td>\n",
       "      <td>1.079</td>\n",
       "      <td>1.529</td>\n",
       "      <td>1.630</td>\n",
       "      <td>30.6</td>\n",
       "      <td>83.8</td>\n",
       "      <td>997.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FORECAST_15_ATRAS  FORECAST_7_ATRAS  FORECAST_2_ATRAS  ESTACION  \\\n",
       "0          25.104820         25.031105         24.801626         1   \n",
       "1          24.997310         24.936530         24.801247         1   \n",
       "2          24.977419         24.728025         24.718630         1   \n",
       "3          24.919670         25.325490         24.706661         1   \n",
       "4          24.971413         25.105440         24.691515         1   \n",
       "\n",
       "            FECHAHORA  ANHO  DIA  MES  HORA  MINUTO  ...  DIA_SEM  AQI_MP2_5  \\\n",
       "0 2021-04-14 13:05:00  2021   14    4    13       5  ...        2       25.0   \n",
       "1 2021-04-14 13:10:00  2021   14    4    13      10  ...        2       25.0   \n",
       "2 2021-04-14 13:15:00  2021   14    4    13      15  ...        2       25.0   \n",
       "3 2021-04-14 13:20:00  2021   14    4    13      20  ...        2       29.0   \n",
       "4 2021-04-14 13:25:00  2021   14    4    13      25  ...        2       29.0   \n",
       "\n",
       "   AQI_MP10  MEDICION_DIA  MP1_ANTERIOR  MP2_5_ANTERIOR MP10_ANTERIOR  \\\n",
       "0       7.0           158         1.449           2.039         2.269   \n",
       "1       7.0           159         1.549           2.089         2.460   \n",
       "2       7.0           160         1.379           2.089         3.259   \n",
       "3       7.0           161         1.309           1.849        12.979   \n",
       "4       7.0           162         1.079           1.529         1.630   \n",
       "\n",
       "  TEMPERATURA_PRONOSTICO  HUMEDAD_PRONOSTICO PRESION_PRONOSTICO  \n",
       "0                   30.7                83.9              997.8  \n",
       "1                   30.4                84.5              997.8  \n",
       "2                   30.4                85.7              997.6  \n",
       "3                   30.2                85.9              997.6  \n",
       "4                   30.6                83.8              997.6  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validacion = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "dias_2 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.25_previous_2.csv')\n",
    "dias_7 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.25_previous_7.csv')\n",
    "dias_15 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_5_horizon_0.25_previous_15.csv')\n",
    "\n",
    "dias_2.rename(columns={'FORECAST': 'FORECAST_2_ATRAS'}, inplace = True)\n",
    "dias_7.rename(columns={'FORECAST': 'FORECAST_7_ATRAS'}, inplace = True)\n",
    "dias_15.rename(columns={'FORECAST': 'FORECAST_15_ATRAS'}, inplace = True)\n",
    "\n",
    "lista_2 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = dias_2[dias_2['ESTACION'] == i]\n",
    "\n",
    "    df_aux.reset_index(inplace = True)\n",
    "\n",
    "    df_aux['indice'] = df_aux.index\n",
    "\n",
    "    #print(df_aux.info())\n",
    "\n",
    "    df_aux_2 = df_aux[df_aux['indice'] > 3743]\n",
    "\n",
    "    #print(df_aux_2.info())\n",
    "\n",
    "    lista_2.append(df_aux_2)\n",
    "\n",
    "dias_2_c = pd.concat(lista_2)\n",
    "dias_2_c.reset_index(inplace = True)\n",
    "\n",
    "print(dias_2_c.info())\n",
    "\n",
    "lista_7 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = dias_7[dias_7['ESTACION'] == i]\n",
    "    \n",
    "    df_aux.reset_index(inplace = True)\n",
    "\n",
    "    df_aux['indice'] = df_aux.index\n",
    "\n",
    "    df_aux_7 = df_aux[df_aux['indice'] > 2303]\n",
    "\n",
    "    lista_7.append(df_aux_7)\n",
    "\n",
    "dias_7_c = pd.concat(lista_7)\n",
    "dias_7_c.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "dias_15.reset_index(inplace = True)\n",
    "\n",
    "lista = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = validacion[validacion['ESTACION'] == i]\n",
    "\n",
    "    first_pred = df_aux.FECHAHORA.min() + relativedelta(days=15)\n",
    "\n",
    "    df_aux = df_aux[df_aux['FECHAHORA'] >= first_pred]\n",
    "\n",
    "    lista.append(df_aux)\n",
    "\n",
    "df = pd.concat(lista)\n",
    "\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "df_2_c = dias_2_c.FORECAST_2_ATRAS\n",
    "df_7_c = dias_7_c.FORECAST_7_ATRAS\n",
    "df_15 = dias_15.FORECAST_15_ATRAS\n",
    "\n",
    "df = pd.merge(df_2_c, df, right_index = True, left_index=True)\n",
    "df = pd.merge(df_7_c, df, right_index = True,  left_index=True)\n",
    "df = pd.merge(df_15, df, right_index=True, left_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "\n",
    "    fig_val = go.Figure()\n",
    "\n",
    "    df_grafica = df[df['ESTACION'] == i]\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.AQI_MP2_5), x = list(df_grafica.FECHAHORA), name = 'AQI Real'))\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_2_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 2 días atrás'))\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_7_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 7 días atrás'))\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_15_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 15 días atrás'))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=\"Title\",\n",
    "        xaxis=dict(\n",
    "            title=\"X Label\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Y label\"\n",
    "        ) ) \n",
    "\n",
    "    fig_val.update_layout( \n",
    "                            title={\n",
    "                                'text': \"Estación \" + str(i) + \". AQI real vs Predicciones a 12 horas\",\n",
    "                                'y':0.9,\n",
    "                                'x':0.5,\n",
    "                                'xanchor': 'center',\n",
    "                                'yanchor': 'top'}, \n",
    "                        yaxis_title = 'AQI MP2.5', \n",
    "                        xaxis_title = 'Fecha',\n",
    "                        legend_title = 'Referencias',\n",
    "                            font=dict(\n",
    "                                    size=16,\n",
    "                                        ),\n",
    "                        )\n",
    "\n",
    "    fig_val.write_html('graphs/XGBOOST/experimento_full/12hsestacion_'+str(i)+'_AQI_vs_prediccion_12hs_2dias_7dias_15dias_resample5min.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICAS - 24 HORAS DE PREDICCION - MEJORES RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36960 entries, 0 to 36959\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   level_0           36960 non-null  int64  \n",
      " 1   index             36960 non-null  int64  \n",
      " 2   Unnamed: 0        36960 non-null  int64  \n",
      " 3   TARGET            36960 non-null  float64\n",
      " 4   FORECAST_2_ATRAS  36960 non-null  float64\n",
      " 5   ESTACION          36960 non-null  int64  \n",
      " 6   indice            36960 non-null  int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 2.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36970 entries, 0 to 36969\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Unnamed: 0   36970 non-null  int64         \n",
      " 1   ESTACION     36970 non-null  float64       \n",
      " 2   MP1          36970 non-null  float64       \n",
      " 3   MP2_5        36970 non-null  float64       \n",
      " 4   MP10         36970 non-null  float64       \n",
      " 5   TEMPERATURA  36970 non-null  float64       \n",
      " 6   HUMEDAD      36970 non-null  float64       \n",
      " 7   PRESION      36970 non-null  float64       \n",
      " 8   TRAFICO      36970 non-null  float64       \n",
      " 9   TIPO         36970 non-null  float64       \n",
      " 10  DIA_SEM      36970 non-null  float64       \n",
      " 11  AQI_MP2_5    36970 non-null  float64       \n",
      " 12  AQI_MP10     36970 non-null  float64       \n",
      " 13  ANHO         36970 non-null  int64         \n",
      " 14  MES          36970 non-null  int64         \n",
      " 15  DIA          36970 non-null  int64         \n",
      " 16  HORA         36970 non-null  int64         \n",
      " 17  MINUTO       36970 non-null  int64         \n",
      " 18  FECHAHORA    36970 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(12), int64(6)\n",
      "memory usage: 5.4 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FORECAST_15_ATRAS</th>\n",
       "      <th>FORECAST_7_ATRAS</th>\n",
       "      <th>FORECAST_2_ATRAS</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MP1</th>\n",
       "      <th>MP2_5</th>\n",
       "      <th>MP10</th>\n",
       "      <th>TEMPERATURA</th>\n",
       "      <th>HUMEDAD</th>\n",
       "      <th>...</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>DIA_SEM</th>\n",
       "      <th>AQI_MP2_5</th>\n",
       "      <th>AQI_MP10</th>\n",
       "      <th>ANHO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>MINUTO</th>\n",
       "      <th>FECHAHORA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.643347</td>\n",
       "      <td>24.376911</td>\n",
       "      <td>24.596104</td>\n",
       "      <td>720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.069333</td>\n",
       "      <td>2.705667</td>\n",
       "      <td>4.812667</td>\n",
       "      <td>32.350000</td>\n",
       "      <td>56.883333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-14 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.501448</td>\n",
       "      <td>24.314358</td>\n",
       "      <td>24.074400</td>\n",
       "      <td>721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.585833</td>\n",
       "      <td>2.039167</td>\n",
       "      <td>2.596167</td>\n",
       "      <td>32.633333</td>\n",
       "      <td>56.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>2021-04-14 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.355524</td>\n",
       "      <td>24.477950</td>\n",
       "      <td>24.482935</td>\n",
       "      <td>722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.311000</td>\n",
       "      <td>1.737500</td>\n",
       "      <td>2.610833</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>57.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-14 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.827559</td>\n",
       "      <td>24.253315</td>\n",
       "      <td>24.169080</td>\n",
       "      <td>723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.909167</td>\n",
       "      <td>2.584167</td>\n",
       "      <td>5.390833</td>\n",
       "      <td>32.583333</td>\n",
       "      <td>56.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>2021-04-14 14:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.699274</td>\n",
       "      <td>23.802975</td>\n",
       "      <td>24.651580</td>\n",
       "      <td>724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.277833</td>\n",
       "      <td>2.754333</td>\n",
       "      <td>3.699167</td>\n",
       "      <td>31.633333</td>\n",
       "      <td>60.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-14 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FORECAST_15_ATRAS  FORECAST_7_ATRAS  FORECAST_2_ATRAS  Unnamed: 0  \\\n",
       "0          24.643347         24.376911         24.596104         720   \n",
       "1          24.501448         24.314358         24.074400         721   \n",
       "2          24.355524         24.477950         24.482935         722   \n",
       "3          24.827559         24.253315         24.169080         723   \n",
       "4          23.699274         23.802975         24.651580         724   \n",
       "\n",
       "   ESTACION       MP1     MP2_5      MP10  TEMPERATURA    HUMEDAD  ...  TIPO  \\\n",
       "0       1.0  2.069333  2.705667  4.812667    32.350000  56.883333  ...   1.0   \n",
       "1       1.0  1.585833  2.039167  2.596167    32.633333  56.400000  ...   1.0   \n",
       "2       1.0  1.311000  1.737500  2.610833    32.400000  57.066667  ...   1.0   \n",
       "3       1.0  1.909167  2.584167  5.390833    32.583333  56.983333  ...   1.0   \n",
       "4       1.0  2.277833  2.754333  3.699167    31.633333  60.533333  ...   1.0   \n",
       "\n",
       "   DIA_SEM  AQI_MP2_5  AQI_MP10  ANHO  MES  DIA  HORA  MINUTO  \\\n",
       "0      2.0  26.333333       7.0  2021    4   14    13       0   \n",
       "1      2.0  29.000000       7.0  2021    4   14    13      30   \n",
       "2      2.0  29.000000       7.0  2021    4   14    14       0   \n",
       "3      2.0  29.000000       7.0  2021    4   14    14      30   \n",
       "4      2.0  29.000000       7.0  2021    4   14    15       0   \n",
       "\n",
       "            FECHAHORA  \n",
       "0 2021-04-14 13:00:00  \n",
       "1 2021-04-14 13:30:00  \n",
       "2 2021-04-14 14:00:00  \n",
       "3 2021-04-14 14:30:00  \n",
       "4 2021-04-14 15:00:00  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validacion = pd.read_csv('datos/experimento_full/test_resample_30_minutes.csv', parse_dates=['FECHAHORA'])\n",
    "dias_2 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_30_horizon_0.25_previous_2.csv')\n",
    "dias_7 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_30_horizon_0.25_previous_7.csv')\n",
    "dias_15 = pd.read_csv('datos/experimento_full/predicciones_10estaciones_resample_30_horizon_0.25_previous_15.csv')\n",
    "\n",
    "dias_2.rename(columns={'FORECAST': 'FORECAST_2_ATRAS'}, inplace = True)\n",
    "dias_7.rename(columns={'FORECAST': 'FORECAST_7_ATRAS'}, inplace = True)\n",
    "dias_15.rename(columns={'FORECAST': 'FORECAST_15_ATRAS'}, inplace = True)\n",
    "\n",
    "lista_2 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = dias_2[dias_2['ESTACION'] == i]\n",
    "\n",
    "    df_aux.reset_index(inplace = True)\n",
    "\n",
    "    df_aux['indice'] = df_aux.index\n",
    "\n",
    "    #print(df_aux.info())\n",
    "\n",
    "    df_aux_2 = df_aux[df_aux['indice'] > 623]\n",
    "\n",
    "    #print(df_aux_2.info())\n",
    "\n",
    "    lista_2.append(df_aux_2)\n",
    "\n",
    "dias_2_c = pd.concat(lista_2)\n",
    "dias_2_c.reset_index(inplace = True)\n",
    "\n",
    "print(dias_2_c.info())\n",
    "\n",
    "lista_7 = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = dias_7[dias_7['ESTACION'] == i]\n",
    "    \n",
    "    df_aux.reset_index(inplace = True)\n",
    "\n",
    "    df_aux['indice'] = df_aux.index\n",
    "\n",
    "    df_aux_7 = df_aux[df_aux['indice'] > 383]\n",
    "\n",
    "    lista_7.append(df_aux_7)\n",
    "\n",
    "dias_7_c = pd.concat(lista_7)\n",
    "dias_7_c.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "dias_15.reset_index(inplace = True)\n",
    "\n",
    "lista = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_aux = validacion[validacion['ESTACION'] == i]\n",
    "\n",
    "    first_pred = df_aux.FECHAHORA.min() + relativedelta(days=15)\n",
    "\n",
    "    df_aux = df_aux[df_aux['FECHAHORA'] >= first_pred]\n",
    "\n",
    "    lista.append(df_aux)\n",
    "\n",
    "df = pd.concat(lista)\n",
    "\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "df_2_c = dias_2_c.FORECAST_2_ATRAS\n",
    "df_7_c = dias_7_c.FORECAST_7_ATRAS\n",
    "df_15 = dias_15.FORECAST_15_ATRAS\n",
    "\n",
    "df = pd.merge(df_2_c, df, right_index = True, left_index=True)\n",
    "df = pd.merge(df_7_c, df, right_index = True,  left_index=True)\n",
    "df = pd.merge(df_15, df, right_index=True, left_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "\n",
    "    fig_val = go.Figure()\n",
    "\n",
    "    df_grafica = df[df['ESTACION'] == i]\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.AQI_MP2_5), x = list(df_grafica.FECHAHORA), name = 'AQI Real'))\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_2_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 2 días atrás'))\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_7_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 7 días atrás'))\n",
    "\n",
    "    fig_val.add_trace(\n",
    "        go.Scatter( y = list(df_grafica.FORECAST_15_ATRAS), x = list(df_grafica.FECHAHORA), name = 'Predicción AQI - 15 días atrás'))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=\"Title\",\n",
    "        xaxis=dict(\n",
    "            title=\"X Label\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Y label\"\n",
    "        ) ) \n",
    "\n",
    "    fig_val.update_layout( \n",
    "                            title={\n",
    "                                'text': \"Estación \" + str(i) + \". AQI real vs Predicciones a 12 horas\",\n",
    "                                'y':0.9,\n",
    "                                'x':0.5,\n",
    "                                'xanchor': 'center',\n",
    "                                'yanchor': 'top'}, \n",
    "                        yaxis_title = 'AQI MP2.5', \n",
    "                        xaxis_title = 'Fecha',\n",
    "                        legend_title = 'Referencias',\n",
    "                            font=dict(\n",
    "                                    size=16,\n",
    "                                        ),\n",
    "                        )\n",
    "\n",
    "    fig_val.write_html('graphs/XGBOOST/experimento_full/24hsestacion_'+str(i)+'_AQI_vs_prediccion_24hs_2dias_7dias_15dias_resample30min.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIFERENTES VARIABLES - Correlación mayor al 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('datos/230127_train_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "validacion = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "\n",
    "horizon = [0.25, 0.5, 1]\n",
    "resample = [5, 30, 60]\n",
    "previous = [2, 7, 15]\n",
    "\n",
    "# Start resampling\n",
    "\n",
    "for resample_item in resample:\n",
    "\n",
    "    df_test = validacion.copy()\n",
    "    df_train = datos.copy()\n",
    "\n",
    "    df_test.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train = df_train.set_index('FECHAHORA', drop = True)\n",
    "    df_test = df_test.set_index('FECHAHORA', drop = True)\n",
    "\n",
    "    lista_resample = []\n",
    "\n",
    "    if resample_item != 5: \n",
    "\n",
    "        r_i = str(resample_item) + 'T'\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_train[df_train['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_train = pd.concat(lista_resample)\n",
    "\n",
    "        lista_resample = []\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_test[df_test['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_test = pd.concat(lista_resample)\n",
    "\n",
    "    df_test['ANHO'] = df_test.index.year\n",
    "    df_test['MES'] = df_test.index.month\n",
    "    df_test['DIA'] = df_test.index.day\n",
    "    df_test['HORA'] = df_test.index.hour\n",
    "    df_test['MINUTO'] = df_test.index.minute\n",
    "    df_test['FECHAHORA'] = df_test.index\n",
    "    df_test.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    df_train['ANHO'] = df_train.index.year\n",
    "    df_train['MES'] = df_train.index.month\n",
    "    df_train['HORA'] = df_train.index.hour\n",
    "    df_train['MINUTO'] = df_train.index.minute\n",
    "    df_train['DIA'] = df_train.index.day\n",
    "    df_train['FECHAHORA'] = df_train.index\n",
    "    df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    df_test.to_csv('datos/experimento_full/test_resample_'+str(resample_item)+'_minutes.csv')\n",
    "    df_train.to_csv('datos/experimento_full/train_resample_'+str(resample_item)+'_minutes.csv')\n",
    "\n",
    "    # OPTUNA\n",
    "\n",
    "    for previous_item in previous:\n",
    "        for horizon_item in horizon:\n",
    "            \n",
    "            estacion = 4\n",
    "\n",
    "            variables = ['MES', 'MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5', 'HUMEDAD', \n",
    "                        'PRESION', 'TEMPERATURA','DIA_SEM']\n",
    "\n",
    "            dependent = ['AQI_MP2_5']\n",
    "\n",
    "            number_of_features = len(variables)\n",
    "\n",
    "            training_days = previous_item\n",
    "            forecast_days = horizon_item\n",
    "\n",
    "            if resample_item == 5:\n",
    "                samples_per_day = 288\n",
    "            elif resample_item == 30:\n",
    "                samples_per_day = 48\n",
    "            elif resample_item == 60:\n",
    "                samples_per_day = 24\n",
    "\n",
    "            step = forecast_days*samples_per_day\n",
    "\n",
    "            train_months = relativedelta(months = 12)\n",
    "\n",
    "            input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "            output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "            train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "            X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                                estacion,\n",
    "                                                                train_months, \n",
    "                                                                variables, \n",
    "                                                                dependent, \n",
    "                                                                train_test_samples, \n",
    "                                                                input_samples, \n",
    "                                                                output_samples, \n",
    "                                                                number_of_features,\n",
    "                                                                step)\n",
    "\n",
    "            def objective(trial):\n",
    "    \n",
    "                params = {\n",
    "                    'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "                    'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 10, 300),\n",
    "                    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                    'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
    "                    'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "                    'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "                }\n",
    "                \n",
    "                optuna_xgb_model = xgb.XGBRegressor(** params)\n",
    "                \n",
    "                trained_xgb_model = MultiOutputRegressor(optuna_xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_test)\n",
    "                print('MAPE: ', MAPE)\n",
    "                MAE = np.mean(np.abs(prediction - y_test))\n",
    "                print('MAE: ', MAE)\n",
    "\n",
    "                MSE = mean_squared_error(prediction, y_test)\n",
    "                \n",
    "                return MSE\n",
    "\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "\n",
    "            study.optimize(objective, n_trials = 100 )\n",
    "\n",
    "            trial = study.best_trial\n",
    "\n",
    "            joblib.dump(study, \"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_mejoresparam_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "            # VALIDATION\n",
    "\n",
    "            # study = joblib.load(\"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "            params = study.best_params\n",
    "\n",
    "            predicciones = {}\n",
    "            metricas = {}\n",
    "            \n",
    "            for i in range(1,11):\n",
    "\n",
    "                estacion = i\n",
    "\n",
    "                X_train_val, y_train_val = utils_xgboost.get_validation(df_test, \n",
    "                                                                        estacion,\n",
    "                                                                        variables, \n",
    "                                                                        dependent, \n",
    "                                                                        train_test_samples, \n",
    "                                                                        input_samples, \n",
    "                                                                        output_samples, \n",
    "                                                                        number_of_features,\n",
    "                                                                        step)\n",
    "                xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "                trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                prediction = trained_xgb_model.predict(X_train_val)\n",
    "                \n",
    "                # guardamos los valores predecidos vs reales en un diccionario\n",
    "                \n",
    "                predicciones[i] = {'real' : y_train_val, 'prediccion': prediction}\n",
    "\n",
    "\n",
    "                pickle.dump(trained_xgb_model, open('models/models_xgboost/experimento_full/xgboost_mejoresparam_estacion_' + str(i) + '_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.pkl', 'wb'))\n",
    "\n",
    "                mean_real = y_train_val.mean()\n",
    "                mean_prediction = prediction.mean()\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_train_val)\n",
    "                MAE = mean_absolute_error(prediction, y_train_val)\n",
    "                RMSE = mean_squared_error(prediction, y_train_val, squared = False)\n",
    "                \n",
    "                # guardamos las metricas en un diccionario\n",
    "                \n",
    "                metricas[i] = {'MAE': MAE, \"MAPE\": MAPE, 'RMSE': RMSE, 'Media real' : mean_real, 'Media predecida': mean_prediction}\n",
    "\n",
    "            df_metricas = pd.DataFrame.from_dict(metricas)\n",
    "\n",
    "            df_metricas.to_csv('metrics/XGBOOST/experimento_full/xgboost_experimento_full_mejoresparam_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "            list_dfs = []\n",
    "\n",
    "            for station in range(1,11):\n",
    "                d = {'TARGET': predicciones[station]['real'].flatten(), 'FORECAST': predicciones[station]['prediccion'].flatten()}\n",
    "                df_aux = pd.DataFrame(data = d)\n",
    "                df_aux['ESTACION'] = station\n",
    "                list_dfs.append(df_aux)\n",
    "\n",
    "            df_predicciones = pd.concat(list_dfs)\n",
    "\n",
    "            df_predicciones.to_csv('datos/experimento_full/predicciones_10estaciones_mejoresparam_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "            print('study_'+ str(resample_item)+'_'+str(horizon_item)+'_'+ str(previous_item)+' done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELACION MAYOR AL 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('datos/230127_train_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "validacion = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "\n",
    "horizon = [0.25, 0.5, 1]\n",
    "resample = [5, 30, 60]\n",
    "previous = [2, 7, 15]\n",
    "\n",
    "# Start resampling\n",
    "\n",
    "for resample_item in resample:\n",
    "\n",
    "    df_test = validacion.copy()\n",
    "    df_train = datos.copy()\n",
    "\n",
    "    df_test.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train = df_train.set_index('FECHAHORA', drop = True)\n",
    "    df_test = df_test.set_index('FECHAHORA', drop = True)\n",
    "\n",
    "    lista_resample = []\n",
    "\n",
    "    if resample_item != 5: \n",
    "\n",
    "        r_i = str(resample_item) + 'T'\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_train[df_train['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_train = pd.concat(lista_resample)\n",
    "\n",
    "        lista_resample = []\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_test[df_test['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_test = pd.concat(lista_resample)\n",
    "\n",
    "    df_test['ANHO'] = df_test.index.year\n",
    "    df_test['MES'] = df_test.index.month\n",
    "    df_test['DIA'] = df_test.index.day\n",
    "    df_test['HORA'] = df_test.index.hour\n",
    "    df_test['MINUTO'] = df_test.index.minute\n",
    "    df_test['FECHAHORA'] = df_test.index\n",
    "    df_test.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    df_train['ANHO'] = df_train.index.year\n",
    "    df_train['MES'] = df_train.index.month\n",
    "    df_train['HORA'] = df_train.index.hour\n",
    "    df_train['MINUTO'] = df_train.index.minute\n",
    "    df_train['DIA'] = df_train.index.day\n",
    "    df_train['FECHAHORA'] = df_train.index\n",
    "    df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    df_test.to_csv('datos/experimento_full/test_resample_'+str(resample_item)+'_minutes.csv')\n",
    "    df_train.to_csv('datos/experimento_full/train_resample_'+str(resample_item)+'_minutes.csv')\n",
    "\n",
    "    # OPTUNA\n",
    "\n",
    "    for previous_item in previous:\n",
    "        for horizon_item in horizon:\n",
    "            \n",
    "            estacion = 4\n",
    "\n",
    "            variables = ['MES', 'MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5', 'HUMEDAD', \n",
    "                        'PRESION', 'TEMPERATURA','DIA_SEM']\n",
    "\n",
    "            dependent = ['AQI_MP2_5']\n",
    "\n",
    "            number_of_features = len(variables)\n",
    "\n",
    "            training_days = previous_item\n",
    "            forecast_days = horizon_item\n",
    "\n",
    "            if resample_item == 5:\n",
    "                samples_per_day = 288\n",
    "            elif resample_item == 30:\n",
    "                samples_per_day = 48\n",
    "            elif resample_item == 60:\n",
    "                samples_per_day = 24\n",
    "\n",
    "            step = forecast_days*samples_per_day\n",
    "\n",
    "            train_months = relativedelta(months = 12)\n",
    "\n",
    "            input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "            output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "            train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "            X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                                estacion,\n",
    "                                                                train_months, \n",
    "                                                                variables, \n",
    "                                                                dependent, \n",
    "                                                                train_test_samples, \n",
    "                                                                input_samples, \n",
    "                                                                output_samples, \n",
    "                                                                number_of_features,\n",
    "                                                                step)\n",
    "\n",
    "            def objective(trial):\n",
    "    \n",
    "                params = {\n",
    "                    'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "                    'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "                    'n_estimators': trial.suggest_int('n_estimators', 10, 300),\n",
    "                    'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                    'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
    "                    'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "                    'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "                }\n",
    "                \n",
    "                optuna_xgb_model = xgb.XGBRegressor(** params)\n",
    "                \n",
    "                trained_xgb_model = MultiOutputRegressor(optuna_xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_test)\n",
    "                print('MAPE: ', MAPE)\n",
    "                MAE = np.mean(np.abs(prediction - y_test))\n",
    "                print('MAE: ', MAE)\n",
    "\n",
    "                MSE = mean_squared_error(prediction, y_test)\n",
    "                \n",
    "                return MSE\n",
    "\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "\n",
    "            study.optimize(objective, n_trials = 100 )\n",
    "\n",
    "            trial = study.best_trial\n",
    "\n",
    "            joblib.dump(study, \"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_mejoresparam_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "            # VALIDATION\n",
    "\n",
    "            # study = joblib.load(\"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "            params = study.best_params\n",
    "\n",
    "            predicciones = {}\n",
    "            metricas = {}\n",
    "            \n",
    "            for i in range(1,11):\n",
    "\n",
    "                estacion = i\n",
    "\n",
    "                X_train_val, y_train_val = utils_xgboost.get_validation(df_test, \n",
    "                                                                        estacion,\n",
    "                                                                        variables, \n",
    "                                                                        dependent, \n",
    "                                                                        train_test_samples, \n",
    "                                                                        input_samples, \n",
    "                                                                        output_samples, \n",
    "                                                                        number_of_features,\n",
    "                                                                        step)\n",
    "                xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "                trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                prediction = trained_xgb_model.predict(X_train_val)\n",
    "                \n",
    "                # guardamos los valores predecidos vs reales en un diccionario\n",
    "                \n",
    "                predicciones[i] = {'real' : y_train_val, 'prediccion': prediction}\n",
    "\n",
    "\n",
    "                pickle.dump(trained_xgb_model, open('models/models_xgboost/experimento_full/xgboost_mejoresparam_estacion_' + str(i) + '_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.pkl', 'wb'))\n",
    "\n",
    "                mean_real = y_train_val.mean()\n",
    "                mean_prediction = prediction.mean()\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_train_val)\n",
    "                MAE = mean_absolute_error(prediction, y_train_val)\n",
    "                RMSE = mean_squared_error(prediction, y_train_val, squared = False)\n",
    "                \n",
    "                # guardamos las metricas en un diccionario\n",
    "                \n",
    "                metricas[i] = {'MAE': MAE, \"MAPE\": MAPE, 'RMSE': RMSE, 'Media real' : mean_real, 'Media predecida': mean_prediction}\n",
    "\n",
    "            df_metricas = pd.DataFrame.from_dict(metricas)\n",
    "\n",
    "            df_metricas.to_csv('metrics/XGBOOST/experimento_full/xgboost_experimento_full_mejoresparam_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "            list_dfs = []\n",
    "\n",
    "            for station in range(1,11):\n",
    "                d = {'TARGET': predicciones[station]['real'].flatten(), 'FORECAST': predicciones[station]['prediccion'].flatten()}\n",
    "                df_aux = pd.DataFrame(data = d)\n",
    "                df_aux['ESTACION'] = station\n",
    "                list_dfs.append(df_aux)\n",
    "\n",
    "            df_predicciones = pd.concat(list_dfs)\n",
    "\n",
    "            df_predicciones.to_csv('datos/experimento_full/predicciones_10estaciones_mejoresparam_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "            print('study_'+ str(resample_item)+'_'+str(horizon_item)+'_'+ str(previous_item)+' done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
