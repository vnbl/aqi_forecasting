{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc8fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "import numpy as np # for data manipulation\n",
    "\n",
    "# Training utils\n",
    "# import utils_xgboost\n",
    "\n",
    "# Optuna\n",
    "# import optuna\n",
    "\n",
    "# Tiempo\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta, MO\n",
    "\n",
    "# # Modelos\n",
    "# from sklearn.linear_model import LinearRegression # for building a linear regression model\n",
    "# from sklearn.svm import SVR # for building SVR model\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metricas\n",
    "# from sklearn.metrics import mean_absolute_error #MAE\n",
    "# from sklearn.metrics import mean_absolute_percentage_error #MAPE\n",
    "# from sklearn.metrics import mean_squared_error #MSE, para RMSE: squared = False\n",
    "\n",
    "# Visualizations\n",
    "import plotly.graph_objects as go # for data visualization\n",
    "import plotly.express as px # for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407deb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('datos/230109_con_MP_DIA_ANTERIOR.csv', parse_dates = ['FECHAHORA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d919b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad6541",
   "metadata": {},
   "source": [
    "# Paso 1: Eliminamos datos MP_ANTERIOR y agregamos PRONOSTICOS CLIMATICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc972cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones = []\n",
    "for i in range(1, 11):\n",
    "    estaciones.append(datos[datos['ESTACION'] == i])\n",
    "    \n",
    "estaciones[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "df_lista = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    df_i = estaciones[i].copy()\n",
    "    df_i = df_i.sort_values(by = ['FECHAHORA'])\n",
    "    df_i = df_i.reset_index(drop = True)\n",
    "#     num_filas = df_i.shape[0]\n",
    "    \n",
    "    # Identifico el indice de la ultima medicion y la de un dia despues\n",
    "    last_index = df_i.index[-1]\n",
    "    day_before_index = df_i.index[-289]\n",
    "    \n",
    "    # elimino el ultimo dia de mediciones \n",
    "    df_final = df_i.drop(list(range(last_index, day_before_index, -1)))\n",
    "    df_final = df_final.reset_index(drop = True)\n",
    "    \n",
    "    # creo un df auxiliar con solo las mediciones de temp, humedad y presion y elimino las primeras 288 filas\n",
    "    \n",
    "    df_i_thp = df_i[['TEMPERATURA', 'HUMEDAD', 'PRESION']].drop(list(range(0, 288)))\n",
    "\n",
    "    df_i_thp = df_i_thp.reset_index(drop = True)\n",
    "\n",
    "    df_final[['TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO']] = df_i_thp\n",
    "    \n",
    "    df_lista.append(df_final)\n",
    "    \n",
    "df = pd.concat(df_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "e = 3\n",
    "\n",
    "e_df = df[df['ESTACION'] == e]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter( x = list(e_df.FECHAHORA), y = list(e_df.HUMEDAD), name = 'HUMEDAD'))\n",
    "fig.add_trace(\n",
    "    go.Scatter( x = list(e_df.FECHAHORA), y = list(e_df.HUMEDAD_PRONOSTICO), name = 'PRONOSTICO'))\n",
    "\n",
    "fig.update_layout( title_text = \"HUMEDAD VS PRONOSTICO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258276b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkeamos que tenga todo lo que tiene que tener\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7dbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el dataframe completito\n",
    "\n",
    "df.to_csv('datos/230127_CON_PRONOSTICOS_THP.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e0370",
   "metadata": {},
   "source": [
    "# Paso 2: Seleccionamos solo datos de los primeros 18 meses de mediciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186be20",
   "metadata": {},
   "source": [
    "## Analizamos primero los datos de las estaciones 7 y 10 que tenian faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "e = 7\n",
    "\n",
    "plot_df_val = df[df['ESTACION'] == e]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter( x = list(plot_df_val.FECHAHORA), y = list(plot_df_val.AQI_MP2_5), name = 'AQI'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter( x = list(plot_df_val.FECHAHORA), y = list(plot_df_val.MP2_5), name = 'MP2.5'))\n",
    "\n",
    "fig.update_layout( title_text = \"Estacion \"+str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2371a",
   "metadata": {},
   "source": [
    "Estacion 7: Hasta 30 de octubre 2020. Desde 8 de abril 2019\n",
    "\n",
    "Estacion 10: Hasta 22 de octubre. Desde 31 de marzo 2019\n",
    "\n",
    "## Vemos que justo alcanza los 18 meses. Entonces hacemos una BD con solo los datos de los primeros 18 meses de cada estacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones = []\n",
    "for i in range(1, 11):\n",
    "    estaciones = range(1, 11)\n",
    "    \n",
    "df_lista = []\n",
    "    \n",
    "for i in estaciones:\n",
    "    print('estacion ' + str(i))\n",
    "    df_i = df[df['ESTACION'] == i].copy()\n",
    "    fecha_1 = df_i.FECHAHORA.min()\n",
    "    print(fecha_1)\n",
    "    delta = relativedelta(months = 18)\n",
    "    fecha_n = fecha_1 + delta\n",
    "    print(fecha_n)\n",
    "    print('\\n')\n",
    "    \n",
    "    df_i = df_i[df_i['FECHAHORA'] <= fecha_n]\n",
    "    df_lista.append(df_i)\n",
    "    \n",
    "df_18 = pd.concat(df_lista)\n",
    "\n",
    "df_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c264c0e2",
   "metadata": {},
   "source": [
    "## Separamos en df_train y df_test\n",
    "\n",
    "df_train = 15 meses\n",
    "\n",
    "\n",
    "df_test = 3 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_train = relativedelta(months = 15)\n",
    "\n",
    "df_train_list = []\n",
    "df_test_list = []\n",
    "\n",
    "for i in estaciones:\n",
    "    print('estacion ' + str(i))\n",
    "    df_i = df_18[df_18['ESTACION'] == i].copy()\n",
    "    \n",
    "    fecha_1_i = df_i.FECHAHORA.min()\n",
    "    print(fecha_1_i)\n",
    "    \n",
    "    fecha_n_i = fecha_1_i + delta_train\n",
    "    print(fecha_n_i)\n",
    "    print('\\n')\n",
    "    \n",
    "    df_train_i = df_i[df_i['FECHAHORA'] <= fecha_n_i]\n",
    "    df_test_i = df_i[df_i['FECHAHORA'] > fecha_n_i]\n",
    "    \n",
    "    df_train_list.append(df_train_i)\n",
    "    df_test_list.append(df_test_i)\n",
    "\n",
    "df_train = pd.concat(df_train_list)\n",
    "df_train = df_train.reset_index(drop = True)\n",
    "df_test = pd.concat(df_test_list)\n",
    "df_test = df_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkeamos df_train y df_test\n",
    "\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87095801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('datos/230127_train_ESTACIONES.csv', index = False)\n",
    "df_test.to_csv('datos/230127_test_ESTACIONES.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultimo check \n",
    "\n",
    "train = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates = ['FECHAHORA'])\n",
    "\n",
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
