{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fer\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "import os\n",
    "\n",
    "new_directory = r'c://Users//Fer//TESIS_ARCHIVOS//TESIS_AIRE//MP_Forecasting//aqi_forecasting//notebooks'\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "import numpy as np # for data manipulation\n",
    "\n",
    "\n",
    "# Training utils\n",
    "from training_code.utils import utils_xgboost\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Tiempo\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta, MO\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression # for building a linear regression model\n",
    "from sklearn.svm import SVR # for building SVR model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import mean_absolute_error #MAE\n",
    "from sklearn.metrics import mean_absolute_percentage_error #MAPE\n",
    "from sklearn.metrics import mean_squared_error #MSE, para RMSE: squared = False\n",
    "\n",
    "# Visualizations\n",
    "import plotly.graph_objects as go # for data visualization\n",
    "import plotly.express as px # for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('datos/230127_train_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "validacion = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = [0.25]\n",
    "resample = [5]\n",
    "previous = [2]\n",
    "\n",
    "stations = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Start resampling\n",
    "\n",
    "for resample_item in resample:\n",
    "\n",
    "    df_train = datos.copy()\n",
    "\n",
    "    df_train.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train = df_train.set_index('FECHAHORA', drop = True)\n",
    "\n",
    "    lista_resample = []\n",
    "\n",
    "    if resample_item != 5: \n",
    "\n",
    "        r_i = str(resample_item) + 'T'\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_train[df_train['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_train = pd.concat(lista_resample)\n",
    "\n",
    "    df_train['ANHO'] = df_train.index.year\n",
    "    df_train['MES'] = df_train.index.month\n",
    "    df_train['HORA'] = df_train.index.hour\n",
    "    df_train['MINUTO'] = df_train.index.minute\n",
    "    df_train['DIA'] = df_train.index.day\n",
    "    df_train['FECHAHORA'] = df_train.index\n",
    "    df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    #df_train.to_csv('datos/experimento_full/train_resample_'+str(resample_item)+'_minutes.csv')\n",
    "\n",
    "    # OPTUNA\n",
    "\n",
    "    for previous_item in previous:\n",
    "        for horizon_item in horizon:\n",
    "\n",
    "            for station_item in stations:\n",
    "\n",
    "                estacion = station_item\n",
    "\n",
    "                variables = ['MP1', 'MP2_5', 'MP10' 'AQI_MP10', 'AQI_MP2_5']\n",
    "\n",
    "                dependent = ['AQI_MP2_5']\n",
    "\n",
    "                number_of_features = len(variables)\n",
    "\n",
    "                training_days = previous_item\n",
    "                forecast_days = horizon_item\n",
    "\n",
    "                if resample_item == 5:\n",
    "                    samples_per_day = 288\n",
    "                elif resample_item == 30:\n",
    "                    samples_per_day = 48\n",
    "                elif resample_item == 60:\n",
    "                    samples_per_day = 24\n",
    "\n",
    "                step = forecast_days*samples_per_day\n",
    "\n",
    "                train_months = relativedelta(months = 12)\n",
    "\n",
    "                input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "                output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "                train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "                X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                                    estacion,\n",
    "                                                                    train_months, \n",
    "                                                                    variables, \n",
    "                                                                    dependent, \n",
    "                                                                    train_test_samples, \n",
    "                                                                    input_samples, \n",
    "                                                                    output_samples, \n",
    "                                                                    number_of_features,\n",
    "                                                                    step)\n",
    "\n",
    "\n",
    "                def objective(trial):\n",
    "        \n",
    "                    params = {\n",
    "                        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "                        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "                        'n_estimators': trial.suggest_int('n_estimators', 10, 300),\n",
    "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
    "                        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "                        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "                    }\n",
    "                    \n",
    "                    optuna_xgb_model = xgb.XGBRegressor(** params)\n",
    "                    \n",
    "                    trained_xgb_model = MultiOutputRegressor(optuna_xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "                    MAPE = mean_absolute_percentage_error(prediction, y_test)\n",
    "                    print('MAPE: ', MAPE)\n",
    "                    MAE = np.mean(np.abs(prediction - y_test))\n",
    "                    print('MAE: ', MAE)\n",
    "\n",
    "                    MSE = mean_squared_error(prediction, y_test)\n",
    "                    \n",
    "                    return MSE\n",
    "\n",
    "                study = optuna.create_study(direction='minimize')\n",
    "\n",
    "                study.optimize(objective, n_trials = 100 )\n",
    "\n",
    "                trial = study.best_trial\n",
    "\n",
    "                joblib.dump(study, \"optuna_studies/XGBOOST/experimento_full/estacion_\"+str(station_item)+\"_study_XGBOOST_mejoresparam40_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "                # VALIDATION\n",
    "\n",
    "                params = study.best_params\n",
    "\n",
    "                # study = joblib.load(\"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "                xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "                trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "                \n",
    "                prediction = trained_xgb_model.predict(X_test)\n",
    "                \n",
    "                predicciones = {}\n",
    "                metricas = {}\n",
    "                # guardamos los valores predecidos vs reales en un diccionario\n",
    "                \n",
    "                predicciones[station_item] = {'real' : y_test, 'prediccion': prediction}\n",
    "\n",
    "\n",
    "                mean_real = y_test.mean()\n",
    "                mean_prediction = prediction.mean()\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_test) * 100\n",
    "                MAE = mean_absolute_error(prediction, y_test)\n",
    "                RMSE = mean_squared_error(prediction, y_test, squared = False)\n",
    "                \n",
    "                # guardamos las metricas en un diccionario\n",
    "                \n",
    "                metricas[station_item] = {'MAE': MAE, \"MAPE\": MAPE, 'RMSE': RMSE, 'Media real' : mean_real, 'Media predecida': mean_prediction}\n",
    "\n",
    "            df_metricas = pd.DataFrame.from_dict(metricas)\n",
    "\n",
    "            df_metricas.to_csv('metrics/XGBOOST/experimento_full/todaslasestaciones_menos_4_6hs_experimento_full_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "            list_dfs = []\n",
    "\n",
    "            for i in stations:\n",
    "                d = {'TARGET': predicciones[i]['real'].flatten(), 'FORECAST': predicciones[i]['prediccion'].flatten()}\n",
    "                df_aux = pd.DataFrame(data = d)\n",
    "                df_aux['ESTACION'] = i\n",
    "                list_dfs.append(df_aux)\n",
    "\n",
    "            df_predicciones = pd.concat(list_dfs)\n",
    "\n",
    "            df_predicciones.info()\n",
    "\n",
    "            df_predicciones.to_csv('datos/experimento_full/predicciones_todas_las_estaciones_menos_4_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = [1]\n",
    "resample = [30]\n",
    "previous = [2]\n",
    "\n",
    "stations = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Start resampling\n",
    "\n",
    "for resample_item in resample:\n",
    "\n",
    "    df_train = datos.copy()\n",
    "\n",
    "    df_train.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "    df_train = df_train.set_index('FECHAHORA', drop = True)\n",
    "\n",
    "    lista_resample = []\n",
    "\n",
    "    if resample_item != 5: \n",
    "\n",
    "        r_i = str(resample_item) + 'T'\n",
    "\n",
    "        for station in range(1,11):\n",
    "            df_aux = df_train[df_train['ESTACION'] == station]\n",
    "\n",
    "            df_aux = df_aux.resample(r_i).mean()\n",
    "            lista_resample.append(df_aux)\n",
    "\n",
    "        df_train = pd.concat(lista_resample)\n",
    "\n",
    "    df_train['ANHO'] = df_train.index.year\n",
    "    df_train['MES'] = df_train.index.month\n",
    "    df_train['HORA'] = df_train.index.hour\n",
    "    df_train['MINUTO'] = df_train.index.minute\n",
    "    df_train['DIA'] = df_train.index.day\n",
    "    df_train['FECHAHORA'] = df_train.index\n",
    "    df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    #df_train.to_csv('datos/experimento_full/train_resample_'+str(resample_item)+'_minutes.csv')\n",
    "\n",
    "    # OPTUNA\n",
    "\n",
    "    for previous_item in previous:\n",
    "        for horizon_item in horizon:\n",
    "\n",
    "            for station_item in stations:\n",
    "\n",
    "                estacion = station_item\n",
    "\n",
    "                variables = [\"ANHO\", 'DIA', 'MES', 'HORA', 'MINUTO', 'MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5', 'TIPO', 'TRAFICO', 'HUMEDAD', \n",
    "                        'PRESION', 'TEMPERATURA','DIA_SEM']\n",
    "\n",
    "                dependent = ['AQI_MP2_5']\n",
    "\n",
    "                number_of_features = len(variables)\n",
    "\n",
    "                training_days = previous_item\n",
    "                forecast_days = horizon_item\n",
    "\n",
    "                if resample_item == 5:\n",
    "                    samples_per_day = 288\n",
    "                elif resample_item == 30:\n",
    "                    samples_per_day = 48\n",
    "                elif resample_item == 60:\n",
    "                    samples_per_day = 24\n",
    "\n",
    "                step = forecast_days*samples_per_day\n",
    "\n",
    "                train_months = relativedelta(months = 12)\n",
    "\n",
    "                input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "                output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "                train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "                X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                                    estacion,\n",
    "                                                                    train_months, \n",
    "                                                                    variables, \n",
    "                                                                    dependent, \n",
    "                                                                    train_test_samples, \n",
    "                                                                    input_samples, \n",
    "                                                                    output_samples, \n",
    "                                                                    number_of_features,\n",
    "                                                                    step)\n",
    "\n",
    "\n",
    "                def objective(trial):\n",
    "        \n",
    "                    params = {\n",
    "                        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "                        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "                        'n_estimators': trial.suggest_int('n_estimators', 10, 300),\n",
    "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                        'gamma': trial.suggest_loguniform('gamma', 1e-5, 1.0),\n",
    "                        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "                        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "                    }\n",
    "                    \n",
    "                    optuna_xgb_model = xgb.XGBRegressor(** params)\n",
    "                    \n",
    "                    trained_xgb_model = MultiOutputRegressor(optuna_xgb_model).fit(X_train , y_train)\n",
    "\n",
    "                    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "                    MAPE = mean_absolute_percentage_error(prediction, y_test)\n",
    "                    print('MAPE: ', MAPE)\n",
    "                    MAE = np.mean(np.abs(prediction - y_test))\n",
    "                    print('MAE: ', MAE)\n",
    "\n",
    "                    MSE = mean_squared_error(prediction, y_test)\n",
    "                    \n",
    "                    return MSE\n",
    "\n",
    "                study = optuna.create_study(direction='minimize')\n",
    "\n",
    "                study.optimize(objective, n_trials = 100 )\n",
    "\n",
    "                trial = study.best_trial\n",
    "\n",
    "                joblib.dump(study, \"optuna_studies/XGBOOST/experimento_full/estacion_\"+str(station_item)+\"_study_XGBOOST_mejoresparam40_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "                # VALIDATION\n",
    "\n",
    "                params = study.best_params\n",
    "\n",
    "                # study = joblib.load(\"optuna_studies/XGBOOST/experimento_full/study_XGBOOST_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "                xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "                trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "                \n",
    "                prediction = trained_xgb_model.predict(X_test)\n",
    "                \n",
    "                predicciones = {}\n",
    "                metricas = {}\n",
    "                # guardamos los valores predecidos vs reales en un diccionario\n",
    "                \n",
    "                predicciones[station_item] = {'real' : y_test, 'prediccion': prediction}\n",
    "\n",
    "\n",
    "                mean_real = y_test.mean()\n",
    "                mean_prediction = prediction.mean()\n",
    "\n",
    "                MAPE = mean_absolute_percentage_error(prediction, y_test) * 100\n",
    "                MAE = mean_absolute_error(prediction, y_test)\n",
    "                RMSE = mean_squared_error(prediction, y_test, squared = False)\n",
    "                \n",
    "                # guardamos las metricas en un diccionario\n",
    "                \n",
    "                metricas[station_item] = {'MAE': MAE, \"MAPE\": MAPE, 'RMSE': RMSE, 'Media real' : mean_real, 'Media predecida': mean_prediction}\n",
    "\n",
    "df_metricas = pd.DataFrame.from_dict(metricas)\n",
    "\n",
    "df_metricas.to_csv('metrics/XGBOOST/experimento_full/todaslasestaciones_menos_4_6hs_experimento_full_resample_'+str(resample_item)+'_horizon_'+str(horizon_item)+'_previous_'+str(previous_item)+'.csv')\n",
    "\n",
    "list_dfs = []\n",
    "\n",
    "for i in stations:\n",
    "    d = {'TARGET': predicciones[i]['real'].flatten(), 'FORECAST': predicciones[i]['prediccion'].flatten()}\n",
    "    df_aux = pd.DataFrame(data = d)\n",
    "    df_aux['ESTACION'] = i\n",
    "    list_dfs.append(df_aux)\n",
    "\n",
    "df_predicciones = pd.concat(list_dfs)\n",
    "\n",
    "df_predicciones.info()\n",
    "\n",
    "df_predicciones.to_csv('datos/experimento_full/predicciones_todas_las_estaciones_menos_4_testing.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validacion 6hs - 10 estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1580842 entries, 0 to 264959\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count    Dtype         \n",
      "---  ------                  --------------    -----         \n",
      " 0   ESTACION                1580842 non-null  int64         \n",
      " 1   FECHAHORA               1580842 non-null  datetime64[ns]\n",
      " 2   ANHO                    1580842 non-null  int64         \n",
      " 3   DIA                     1580842 non-null  int64         \n",
      " 4   MES                     1580842 non-null  int64         \n",
      " 5   HORA                    1580842 non-null  int64         \n",
      " 6   MINUTO                  1580842 non-null  int64         \n",
      " 7   MP1                     1580842 non-null  float64       \n",
      " 8   MP2_5                   1580842 non-null  float64       \n",
      " 9   MP10                    1580842 non-null  float64       \n",
      " 10  TEMPERATURA             1580842 non-null  float64       \n",
      " 11  HUMEDAD                 1580842 non-null  float64       \n",
      " 12  PRESION                 1580842 non-null  float64       \n",
      " 13  DIA_TRAF_COD            1580842 non-null  object        \n",
      " 14  TRAFICO_COD             1580842 non-null  object        \n",
      " 15  TRAFICO                 1580842 non-null  int64         \n",
      " 16  TIPO_COD                1580842 non-null  object        \n",
      " 17  TIPO                    1580842 non-null  int64         \n",
      " 18  DIA_SEM                 1580842 non-null  int64         \n",
      " 19  AQI_MP2_5               1580842 non-null  float64       \n",
      " 20  AQI_MP10                1580842 non-null  float64       \n",
      " 21  MEDICION_DIA            1580842 non-null  int64         \n",
      " 22  MP1_ANTERIOR            1580842 non-null  float64       \n",
      " 23  MP2_5_ANTERIOR          1580842 non-null  float64       \n",
      " 24  MP10_ANTERIOR           1580842 non-null  float64       \n",
      " 25  TEMPERATURA_PRONOSTICO  1580842 non-null  float64       \n",
      " 26  HUMEDAD_PRONOSTICO      1580842 non-null  float64       \n",
      " 27  PRESION_PRONOSTICO      1580842 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(10), object(3)\n",
      "memory usage: 349.8+ MB\n"
     ]
    }
   ],
   "source": [
    "lista = [datos,validacion]\n",
    "df = pd.concat(lista)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTACION 1:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 3.202421971033385\n",
      "MAPE:  10.52100872488529\n",
      "RMSE:  4.8534711228923\n",
      "\n",
      "\n",
      "media real:  36.895833333333336\n",
      "media predecida:  36.41405\n",
      "\n",
      "\n",
      "ESTACION 2:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 2.4197551049568036\n",
      "MAPE:  8.144040920238563\n",
      "RMSE:  3.585456067274404\n",
      "\n",
      "\n",
      "media real:  33.37260802469136\n",
      "media predecida:  32.56632\n",
      "\n",
      "\n",
      "ESTACION 3:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 2.7561510776296076\n",
      "MAPE:  6.4389540985370015\n",
      "RMSE:  4.499839014437153\n",
      "\n",
      "\n",
      "media real:  45.66574074074074\n",
      "media predecida:  45.85107\n",
      "\n",
      "\n",
      "ESTACION 5:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 2.2862015185532747\n",
      "MAPE:  7.812749814948501\n",
      "RMSE:  3.8660099478084757\n",
      "\n",
      "\n",
      "media real:  31.298881172839508\n",
      "media predecida:  30.98463\n",
      "\n",
      "\n",
      "ESTACION 6:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 4.295128290557567\n",
      "MAPE:  8.120308467725543\n",
      "RMSE:  7.871595885138699\n",
      "\n",
      "\n",
      "media real:  54.965123456790124\n",
      "media predecida:  53.466026\n",
      "\n",
      "\n",
      "ESTACION 7:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 2.649958249034337\n",
      "MAPE:  8.995116368023703\n",
      "RMSE:  5.378645929980987\n",
      "\n",
      "\n",
      "media real:  30.52835648148148\n",
      "media predecida:  29.705309\n",
      "\n",
      "\n",
      "ESTACION 8:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 3.0934668128505165\n",
      "MAPE:  7.345292752841588\n",
      "RMSE:  5.031127150952751\n",
      "\n",
      "\n",
      "media real:  43.78445216049383\n",
      "media predecida:  43.567158\n",
      "\n",
      "\n",
      "ESTACION 9:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 1.9681480096722095\n",
      "MAPE:  14.565777599476318\n",
      "RMSE:  3.1650710858311344\n",
      "\n",
      "\n",
      "media real:  18.443595679012347\n",
      "media predecida:  18.760666\n",
      "\n",
      "\n",
      "ESTACION 10:\n",
      "prediction shape:  (360, 72)\n",
      "test shape:  (360, 72)\n",
      "MAE : 2.5698998149162455\n",
      "MAPE:  9.9072955649607\n",
      "RMSE:  5.457903401848225\n",
      "\n",
      "\n",
      "media real:  26.787461419753086\n",
      "media predecida:  26.948679\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizon_item = 0.25\n",
    "resample_item = 5\n",
    "previous_item = 2\n",
    "\n",
    "stations = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "predicciones = {}\n",
    "metricas = {}\n",
    "\n",
    "for i in stations:\n",
    "\n",
    "    estacion = i\n",
    "\n",
    "    variables = ['MP1', 'MP2_5','AQI_MP10', 'AQI_MP2_5']\n",
    "\n",
    "    dependent = ['AQI_MP2_5']\n",
    "\n",
    "    number_of_features = len(variables)\n",
    "\n",
    "    training_days = 2 \n",
    "    forecast_days = 1/4\n",
    "    samples_per_day = 288\n",
    "    step = 288/4\n",
    "\n",
    "    # Creamos una variable que nos diga con cuantos meses de entrenamiento queremos contar para el X_train\n",
    "    train_months = relativedelta(months = 15)\n",
    "\n",
    "    input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "    output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "    train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df, \n",
    "                                                                    estacion,\n",
    "                                                                    train_months, \n",
    "                                                                    variables, \n",
    "                                                                    dependent, \n",
    "                                                                    train_test_samples, \n",
    "                                                                    input_samples, \n",
    "                                                                    output_samples, \n",
    "                                                                    number_of_features,\n",
    "                                                                    step)\n",
    "\n",
    "\n",
    "    study = joblib.load(\"optuna_studies/XGBOOST/experimento_full/Validaciones/estacion_\"+str(i)+\"_study_XGBOOST_mejoresparam40_resample_\"+str(resample_item)+\"_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "    params = study.best_params\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    # guardamos los valores predecidos vs reales en un diccionario\n",
    "\n",
    "    predicciones[i] = {'real' : y_test, 'prediccion': prediction}\n",
    "\n",
    "    mean_real = y_test.mean()\n",
    "    mean_prediction = prediction.mean()\n",
    "\n",
    "    MAPE = mean_absolute_percentage_error(prediction, y_test) * 100\n",
    "    MAE = mean_absolute_error(prediction, y_test)\n",
    "    RMSE = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    # guardamos las metricas en un diccionario\n",
    "\n",
    "    metricas[i] = {'MAE': MAE, \"MAPE\": MAPE, 'RMSE': RMSE, 'Media real' : mean_real, 'Media predecida': mean_prediction}\n",
    "\n",
    "    print('ESTACION '+str(i)+':')\n",
    "    print('prediction shape: ', prediction.shape)\n",
    "    print('test shape: ', y_test.shape)\n",
    "    print('MAE :', MAE)\n",
    "    print('MAPE: ', MAPE)\n",
    "    print('RMSE: ', RMSE)\n",
    "    print('\\n')\n",
    "    print('media real: ', mean_real)\n",
    "    print('media predecida: ', mean_prediction)\n",
    "    print('\\n')\n",
    "\n",
    "df_metricas = pd.DataFrame.from_dict(metricas)\n",
    "\n",
    "df_metricas.to_csv('metrics/XGBOOST/experimento_full/validation_xgboost_todaslasestaciones_5_0.25_2.csv')\n",
    "\n",
    "list_dfs = []\n",
    "\n",
    "for i in stations:\n",
    "    d = {'TARGET': predicciones[i]['real'].flatten(), 'FORECAST': predicciones[i]['prediccion'].flatten()}\n",
    "    df_aux = pd.DataFrame(data = d)\n",
    "    df_aux['ESTACION'] = i\n",
    "    list_dfs.append(df_aux)\n",
    "\n",
    "df_predicciones = pd.concat(list_dfs)\n",
    "\n",
    "\n",
    "df_predicciones.to_csv('datos/experimento_full/predicciones_todaslasestaciones_validation_xgboost_5_0.25_2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTACION 1:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 10.404782100702509\n",
      "MAPE:  32.87986538457702\n",
      "RMSE:  13.39423816298831\n",
      "\n",
      "\n",
      "media real:  36.895833333333336\n",
      "media predecida:  33.651154\n",
      "\n",
      "\n",
      "ESTACION 2:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 6.2369663865110025\n",
      "MAPE:  21.481068678294278\n",
      "RMSE:  8.72257603632884\n",
      "\n",
      "\n",
      "media real:  33.37260802469136\n",
      "media predecida:  30.801903\n",
      "\n",
      "\n",
      "ESTACION 3:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 7.124791970370729\n",
      "MAPE:  16.50108850853668\n",
      "RMSE:  9.406605864768617\n",
      "\n",
      "\n",
      "media real:  45.66574074074074\n",
      "media predecida:  45.90638\n",
      "\n",
      "\n",
      "ESTACION 5:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 5.935631191914464\n",
      "MAPE:  20.02892636679644\n",
      "RMSE:  8.613564204261039\n",
      "\n",
      "\n",
      "media real:  31.298881172839508\n",
      "media predecida:  30.577255\n",
      "\n",
      "\n",
      "ESTACION 6:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 11.380868103327574\n",
      "MAPE:  21.449823748716565\n",
      "RMSE:  18.030582388297915\n",
      "\n",
      "\n",
      "media real:  54.965123456790124\n",
      "media predecida:  51.46375\n",
      "\n",
      "\n",
      "ESTACION 7:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 6.845789481129175\n",
      "MAPE:  24.12482625441968\n",
      "RMSE:  10.654597028661412\n",
      "\n",
      "\n",
      "media real:  30.52835648148148\n",
      "media predecida:  29.363607\n",
      "\n",
      "\n",
      "ESTACION 8:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 9.317867615524632\n",
      "MAPE:  22.756237249005355\n",
      "RMSE:  13.251610817018557\n",
      "\n",
      "\n",
      "media real:  43.78445216049383\n",
      "media predecida:  41.92562\n",
      "\n",
      "\n",
      "ESTACION 9:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 5.7566962144809\n",
      "MAPE:  36.28920142922669\n",
      "RMSE:  8.191632246122744\n",
      "\n",
      "\n",
      "media real:  18.443595679012347\n",
      "media predecida:  16.620201\n",
      "\n",
      "\n",
      "ESTACION 10:\n",
      "prediction shape:  (90, 288)\n",
      "test shape:  (90, 288)\n",
      "MAE : 7.541832295446483\n",
      "MAPE:  29.219313724064644\n",
      "RMSE:  13.26710377469629\n",
      "\n",
      "\n",
      "media real:  26.787461419753086\n",
      "media predecida:  24.866852\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lista = [datos,validacion]\n",
    "df = pd.concat(lista)\n",
    "\n",
    "\n",
    "horizon_item = 1\n",
    "resample_item = 5\n",
    "previous_item = 2\n",
    "\n",
    "stations = [1, 2, 3, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "predicciones = {}\n",
    "metricas = {}\n",
    "\n",
    "df_train = df.copy()\n",
    "\n",
    "df_train.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "            'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "            'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "df_train = df_train.set_index('FECHAHORA', drop = True)\n",
    "\n",
    "lista_resample = []\n",
    "\n",
    "if resample_item != 5: \n",
    "\n",
    "    r_i = str(resample_item) + 'T'\n",
    "\n",
    "    for station in range(1,11):\n",
    "        df_aux = df_train[df_train['ESTACION'] == station]\n",
    "\n",
    "        df_aux = df_aux.resample(r_i).mean()\n",
    "        lista_resample.append(df_aux)\n",
    "\n",
    "    df_train = pd.concat(lista_resample)\n",
    "\n",
    "df_train['ANHO'] = df_train.index.year\n",
    "df_train['MES'] = df_train.index.month\n",
    "df_train['HORA'] = df_train.index.hour\n",
    "df_train['MINUTO'] = df_train.index.minute\n",
    "df_train['DIA'] = df_train.index.day\n",
    "df_train['FECHAHORA'] = df_train.index\n",
    "df = df_train.reset_index(drop = True)\n",
    "\n",
    "for i in stations:\n",
    "\n",
    "    estacion = i\n",
    "\n",
    "    variables = ['MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5']\n",
    "\n",
    "    dependent = ['AQI_MP2_5']\n",
    "\n",
    "    number_of_features = len(variables)\n",
    "\n",
    "    training_days = 2 \n",
    "    forecast_days = 1\n",
    "    samples_per_day = 288\n",
    "    step = 288\n",
    "\n",
    "    # Creamos una variable que nos diga con cuantos meses de entrenamiento queremos contar para el X_train\n",
    "    train_months = relativedelta(months = 15)\n",
    "\n",
    "    input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "    output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "    train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df, \n",
    "                                                                    estacion,\n",
    "                                                                    train_months, \n",
    "                                                                    variables, \n",
    "                                                                    dependent, \n",
    "                                                                    train_test_samples, \n",
    "                                                                    input_samples, \n",
    "                                                                    output_samples, \n",
    "                                                                    number_of_features,\n",
    "                                                                    step)\n",
    "\n",
    "\n",
    "    study = joblib.load(\"optuna_studies/XGBOOST/experimento_full/Validaciones/estacion_\"+str(i)+\"_study_XGBOOST_mejoresparam40_resample_30_horizon_\"+str(horizon_item)+\"_previous_\"+str(previous_item)+\".pkl\")\n",
    "\n",
    "    params = study.best_params\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    # guardamos los valores predecidos vs reales en un diccionario\n",
    "\n",
    "    predicciones[i] = {'real' : y_test, 'prediccion': prediction}\n",
    "\n",
    "    mean_real = y_test.mean()\n",
    "    mean_prediction = prediction.mean()\n",
    "\n",
    "    MAPE = mean_absolute_percentage_error(prediction, y_test) * 100\n",
    "    MAE = mean_absolute_error(prediction, y_test)\n",
    "    RMSE = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    # guardamos las metricas en un diccionario\n",
    "\n",
    "    metricas[i] = {'MAE': MAE, \"MAPE\": MAPE, 'RMSE': RMSE, 'Media real' : mean_real, 'Media predecida': mean_prediction}\n",
    "\n",
    "    print('ESTACION '+str(i)+':')\n",
    "    print('prediction shape: ', prediction.shape)\n",
    "    print('test shape: ', y_test.shape)\n",
    "    print('MAE :', MAE)\n",
    "    print('MAPE: ', MAPE)\n",
    "    print('RMSE: ', RMSE)\n",
    "    print('\\n')\n",
    "    print('media real: ', mean_real)\n",
    "    print('media predecida: ', mean_prediction)\n",
    "    print('\\n')\n",
    "\n",
    "df_metricas = pd.DataFrame.from_dict(metricas)\n",
    "\n",
    "df_metricas.to_csv('metrics/XGBOOST/experimento_full/prueba_validation_xgboost_todaslasestaciones_5_1_2.csv')\n",
    "\n",
    "list_dfs = []\n",
    "\n",
    "for i in stations:\n",
    "    d = {'TARGET': predicciones[i]['real'].flatten(), 'FORECAST': predicciones[i]['prediccion'].flatten()}\n",
    "    df_aux = pd.DataFrame(data = d)\n",
    "    df_aux['ESTACION'] = i\n",
    "    list_dfs.append(df_aux)\n",
    "\n",
    "df_predicciones = pd.concat(list_dfs)\n",
    "\n",
    "\n",
    "df_predicciones.to_csv('datos/experimento_full/prueba_predicciones_todaslasestaciones_validation_xgboost_5_1_2.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
