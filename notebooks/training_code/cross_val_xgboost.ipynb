{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fer\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "import os\n",
    "\n",
    "new_directory = r'c://Users//Fer//TESIS_ARCHIVOS//TESIS_AIRE//MP_Forecasting//aqi_forecasting//notebooks'\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "import numpy as np # for data manipulation\n",
    "\n",
    "\n",
    "# Training utils\n",
    "from training_code.utils import utils_xgboost\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Tiempo\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta, MO\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression # for building a linear regression model\n",
    "from sklearn.svm import SVR # for building SVR model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import mean_absolute_error #MAE\n",
    "from sklearn.metrics import mean_absolute_percentage_error #MAPE\n",
    "from sklearn.metrics import mean_squared_error #MSE, para RMSE: squared = False\n",
    "\n",
    "# Visualizations\n",
    "import plotly.graph_objects as go # for data visualization\n",
    "import plotly.express as px # for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ee = pd.read_csv('datos/230127_train_ESTACIONES.csv', parse_dates=['FECHAHORA'])\n",
    "test_ee = pd.read_csv('datos/230127_test_ESTACIONES.csv', parse_dates=['FECHAHORA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ee.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>FECHAHORA</th>\n",
       "      <th>ANHO</th>\n",
       "      <th>DIA</th>\n",
       "      <th>MES</th>\n",
       "      <th>HORA</th>\n",
       "      <th>MINUTO</th>\n",
       "      <th>MP1</th>\n",
       "      <th>MP2_5</th>\n",
       "      <th>MP10</th>\n",
       "      <th>...</th>\n",
       "      <th>DIA_SEM</th>\n",
       "      <th>AQI_MP2_5</th>\n",
       "      <th>AQI_MP10</th>\n",
       "      <th>MEDICION_DIA</th>\n",
       "      <th>MP1_ANTERIOR</th>\n",
       "      <th>MP2_5_ANTERIOR</th>\n",
       "      <th>MP10_ANTERIOR</th>\n",
       "      <th>TEMPERATURA_PRONOSTICO</th>\n",
       "      <th>HUMEDAD_PRONOSTICO</th>\n",
       "      <th>PRESION_PRONOSTICO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-30 13:00:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.839</td>\n",
       "      <td>3.989</td>\n",
       "      <td>4.599</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>157</td>\n",
       "      <td>2.609</td>\n",
       "      <td>3.720</td>\n",
       "      <td>4.519</td>\n",
       "      <td>36.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>995.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-30 13:05:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>9.000</td>\n",
       "      <td>13.079</td>\n",
       "      <td>21.319</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>158</td>\n",
       "      <td>1.919</td>\n",
       "      <td>2.659</td>\n",
       "      <td>10.340</td>\n",
       "      <td>36.7</td>\n",
       "      <td>42.1</td>\n",
       "      <td>994.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-30 13:10:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1.969</td>\n",
       "      <td>2.369</td>\n",
       "      <td>13.170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>159</td>\n",
       "      <td>1.769</td>\n",
       "      <td>2.609</td>\n",
       "      <td>3.419</td>\n",
       "      <td>36.6</td>\n",
       "      <td>43.5</td>\n",
       "      <td>994.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-30 13:15:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>1.740</td>\n",
       "      <td>2.379</td>\n",
       "      <td>2.429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>160</td>\n",
       "      <td>1.480</td>\n",
       "      <td>2.009</td>\n",
       "      <td>2.159</td>\n",
       "      <td>37.0</td>\n",
       "      <td>41.4</td>\n",
       "      <td>994.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-30 13:20:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>2.710</td>\n",
       "      <td>4.119</td>\n",
       "      <td>7.710</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>161</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.909</td>\n",
       "      <td>2.809</td>\n",
       "      <td>37.1</td>\n",
       "      <td>40.6</td>\n",
       "      <td>994.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ESTACION           FECHAHORA  ANHO  DIA  MES  HORA  MINUTO    MP1   MP2_5  \\\n",
       "0         1 2019-12-30 13:00:00  2019   30   12    13       0  2.839   3.989   \n",
       "1         1 2019-12-30 13:05:00  2019   30   12    13       5  9.000  13.079   \n",
       "2         1 2019-12-30 13:10:00  2019   30   12    13      10  1.969   2.369   \n",
       "3         1 2019-12-30 13:15:00  2019   30   12    13      15  1.740   2.379   \n",
       "4         1 2019-12-30 13:20:00  2019   30   12    13      20  2.710   4.119   \n",
       "\n",
       "     MP10  ...  DIA_SEM  AQI_MP2_5  AQI_MP10 MEDICION_DIA MP1_ANTERIOR  \\\n",
       "0   4.599  ...        0       72.0      25.0          157        2.609   \n",
       "1  21.319  ...        0       72.0      25.0          158        1.919   \n",
       "2  13.170  ...        0       72.0      25.0          159        1.769   \n",
       "3   2.429  ...        0       72.0      25.0          160        1.480   \n",
       "4   7.710  ...        0       72.0      25.0          161        1.250   \n",
       "\n",
       "   MP2_5_ANTERIOR MP10_ANTERIOR  TEMPERATURA_PRONOSTICO  HUMEDAD_PRONOSTICO  \\\n",
       "0           3.720         4.519                    36.5                42.8   \n",
       "1           2.659        10.340                    36.7                42.1   \n",
       "2           2.609         3.419                    36.6                43.5   \n",
       "3           2.009         2.159                    37.0                41.4   \n",
       "4           1.909         2.809                    37.1                40.6   \n",
       "\n",
       "   PRESION_PRONOSTICO  \n",
       "0               995.1  \n",
       "1               994.9  \n",
       "2               994.8  \n",
       "3               994.7  \n",
       "4               994.6  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junto = [train_ee, test_ee]\n",
    "\n",
    "datos = pd.concat(junto)\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 158113 entries, 394563 to 105983\n",
      "Data columns (total 28 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   ESTACION                158113 non-null  int64         \n",
      " 1   FECHAHORA               158113 non-null  datetime64[ns]\n",
      " 2   ANHO                    158113 non-null  int64         \n",
      " 3   DIA                     158113 non-null  int64         \n",
      " 4   MES                     158113 non-null  int64         \n",
      " 5   HORA                    158113 non-null  int64         \n",
      " 6   MINUTO                  158113 non-null  int64         \n",
      " 7   MP1                     158113 non-null  float64       \n",
      " 8   MP2_5                   158113 non-null  float64       \n",
      " 9   MP10                    158113 non-null  float64       \n",
      " 10  TEMPERATURA             158113 non-null  float64       \n",
      " 11  HUMEDAD                 158113 non-null  float64       \n",
      " 12  PRESION                 158113 non-null  float64       \n",
      " 13  DIA_TRAF_COD            158113 non-null  object        \n",
      " 14  TRAFICO_COD             158113 non-null  object        \n",
      " 15  TRAFICO                 158113 non-null  int64         \n",
      " 16  TIPO_COD                158113 non-null  object        \n",
      " 17  TIPO                    158113 non-null  int64         \n",
      " 18  DIA_SEM                 158113 non-null  int64         \n",
      " 19  AQI_MP2_5               158113 non-null  float64       \n",
      " 20  AQI_MP10                158113 non-null  float64       \n",
      " 21  MEDICION_DIA            158113 non-null  int64         \n",
      " 22  MP1_ANTERIOR            158113 non-null  float64       \n",
      " 23  MP2_5_ANTERIOR          158113 non-null  float64       \n",
      " 24  MP10_ANTERIOR           158113 non-null  float64       \n",
      " 25  TEMPERATURA_PRONOSTICO  158113 non-null  float64       \n",
      " 26  HUMEDAD_PRONOSTICO      158113 non-null  float64       \n",
      " 27  PRESION_PRONOSTICO      158113 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(10), object(3)\n",
      "memory usage: 35.0+ MB\n"
     ]
    }
   ],
   "source": [
    "e4 = datos[datos['ESTACION'] == 4]\n",
    "\n",
    "e4.FECHAHORA.max()\n",
    "\n",
    "e4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 horas - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val MAPE, MAE, RMSE:\n",
      "0.10624548845816087\n",
      "3.5611293050977917\n",
      "5.139260333803817\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.08419537646581533\n",
      "3.028277209726733\n",
      "4.13499972885405\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.0682377275192539\n",
      "2.6526203446679406\n",
      "3.5242013247507447\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.12512136579509944\n",
      "3.0658148950705475\n",
      "7.532418206983646\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.12465460257555999\n",
      "2.127865969731612\n",
      "2.7871268843485146\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.09328873509342106\n",
      "2.050405872558391\n",
      "2.949560705283904\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.07535471470454384\n",
      "2.2371403544997244\n",
      "3.1863685429191517\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.1106172285783314\n",
      "2.307482436602478\n",
      "3.4348947234257383\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.11017453831237958\n",
      "1.950156140017199\n",
      "2.8563214092753504\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.08855821508274514\n",
      "2.581419974087197\n",
      "3.76658622549937\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "estacion = 4\n",
    "\n",
    "mape = []\n",
    "rmse = []\n",
    "mae = []\n",
    "\n",
    "mape_t = []\n",
    "rmse_t = []\n",
    "mae_t = []\n",
    "\n",
    "variables = ['MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5']\n",
    "dependent = ['AQI_MP2_5']\n",
    "\n",
    "number_of_features = len(variables)\n",
    "\n",
    "forecast_days = 0.25\n",
    "training_days = 2\n",
    "samples_per_day = 288\n",
    "\n",
    "step = forecast_days*samples_per_day\n",
    "\n",
    "input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set_1 = datos[(datos['FECHAHORA']) < (datos.FECHAHORA.min() + relativedelta(months=3))]\n",
    "# print(train_set_1.info())\n",
    "# print(train_set_1.FECHAHORA.min())\n",
    "\n",
    "train_set_2 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=6))]\n",
    "# print(train_set_2.info())\n",
    "# print(train_set_2.FECHAHORA.min())\n",
    "\n",
    "train_set_3 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=9))]\n",
    "# print(train_set_3.FECHAHORA.min())\n",
    "\n",
    "train_set_4 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=12))]\n",
    "#print(train_set_4.FECHAHORA.min())\n",
    "\n",
    "train_set_5 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(years = 1, months = 3))]\n",
    "#print(train_set_5.FECHAHORA.min())\n",
    "\n",
    "test_set_1 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=6)))]\n",
    "\n",
    "test_set_2 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=9)))]\n",
    "\n",
    "test_set_3 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=12)))]\n",
    "\n",
    "test_set_4 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=15)))]\n",
    "\n",
    "test_set_5 = datos\n",
    "\n",
    "set_set = [[train_set_1, 2, test_set_1, 3], [train_set_2, 5, test_set_2, 6], [train_set_3, 8, test_set_3, 9], \n",
    "           [train_set_4, 11, test_set_4, 12], [train_set_5, 14, test_set_5, 15]]\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    train_months = relativedelta(months = set_set[i][1])\n",
    "    df_train = set_set[i][0]\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                        estacion,\n",
    "                                                        train_months, \n",
    "                                                        variables, \n",
    "                                                        dependent, \n",
    "                                                        train_test_samples, \n",
    "                                                        input_samples, \n",
    "                                                        output_samples, \n",
    "                                                        number_of_features,\n",
    "                                                        step)\n",
    "    \n",
    "    params = {'max_depth': 5,\n",
    "              'learning_rate': 0.024093830590526,\n",
    "              'n_estimators': 224,\n",
    "              'min_child_weight': 6,\n",
    "              'gamma':  0.005342041600216,\n",
    "              'subsample': 0.635588411140476,\n",
    "              'colsample_bytree': 0.998857049787802}\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    # validation\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    mape_val = mean_absolute_percentage_error(prediction, y_test)\n",
    "    mae_val = mean_absolute_error(prediction, y_test)\n",
    "    rmse_val = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    print('val MAPE, MAE, RMSE:')\n",
    "\n",
    "    print(mape_val)\n",
    "    print(mae_val)\n",
    "    print(rmse_val)\n",
    "\n",
    "    mape.append(mape_val)\n",
    "    mae.append(mae_val)\n",
    "    rmse.append(rmse_val)\n",
    "\n",
    "    # testing\n",
    "    \n",
    "    train_months = relativedelta(months = set_set[i][3])\n",
    "    df_train = set_set[i][2]\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                        estacion,\n",
    "                                                        train_months, \n",
    "                                                        variables, \n",
    "                                                        dependent, \n",
    "                                                        train_test_samples, \n",
    "                                                        input_samples, \n",
    "                                                        output_samples, \n",
    "                                                        number_of_features,\n",
    "                                                        step)\n",
    "    \n",
    "    # # params = {'max_depth': 5,\n",
    "    #           'learning_rate': 0.024093830590526,\n",
    "    #           'n_estimators': 224,\n",
    "    #           'min_child_weight': 6,\n",
    "    #           'gamma':  0.005342041600216,\n",
    "    #           'subsample': 0.635588411140476,\n",
    "    #           'colsample_bytree': 0.998857049787802}\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    mape_test = mean_absolute_percentage_error(prediction, y_test)\n",
    "    mae_test = mean_absolute_error(prediction, y_test)\n",
    "    rmse_test = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    print('----')\n",
    "    print('test MAPE, MAE, RMSE:')\n",
    "\n",
    "    print(mape_test)\n",
    "    print(mae_test)\n",
    "    print(rmse_test)\n",
    "\n",
    "    print('----')\n",
    "\n",
    "    mape_t.append(mape_test)\n",
    "    mae_t.append(mae_test)\n",
    "    rmse_t.append(rmse_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09693341431397964\n",
      "2.5057824228028536\n",
      "3.4986556990195155\n"
     ]
    }
   ],
   "source": [
    "print(sum(mape)/5)\n",
    "print(sum(mae)/5)\n",
    "print(sum(rmse)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "0.09693341431397964\n",
      "2.5057824228028536\n",
      "3.4986556990195155\n",
      "test\n",
      "0.10035618420308248\n",
      "2.6066800776090693\n",
      "4.363691918009342\n"
     ]
    }
   ],
   "source": [
    "print('val')\n",
    "print(sum(mape)/5)\n",
    "print(sum(mae)/5)\n",
    "print(sum(rmse)/5)\n",
    "\n",
    "print('test')\n",
    "print(sum(mape_t)/5)\n",
    "print(sum(mae_t)/5)\n",
    "print(sum(rmse_t)/5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 horas - validation + testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val MAPE, MAE, RMSE:\n",
      "0.1907580475261047\n",
      "5.96011123428441\n",
      "8.862502627099563\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.1421206813974915\n",
      "5.419319690827773\n",
      "7.022219811727332\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.10928715258178658\n",
      "4.529505797588464\n",
      "5.8745703439132875\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.1867957973361338\n",
      "4.993113176819702\n",
      "10.233168993040133\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.19070427997210782\n",
      "3.5303019098138715\n",
      "4.408990779153277\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.14448701349456702\n",
      "3.496045252903407\n",
      "5.071356564982491\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.1314448471870656\n",
      "4.216131709298195\n",
      "6.272387004405862\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.17106004127923666\n",
      "3.5234870070080597\n",
      "4.900100799176308\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.169111826984098\n",
      "2.860536090653352\n",
      "3.826920361164021\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.14397189469824634\n",
      "4.4419672095481255\n",
      "6.384450705233636\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "estacion = 4\n",
    "\n",
    "mape = []\n",
    "rmse = []\n",
    "mae = []\n",
    "\n",
    "mape_t = []\n",
    "rmse_t = []\n",
    "mae_t = []\n",
    "\n",
    "variables = ['MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5']\n",
    "dependent = ['AQI_MP2_5']\n",
    "\n",
    "number_of_features = len(variables)\n",
    "\n",
    "forecast_days = 0.5\n",
    "training_days = 2\n",
    "samples_per_day = 288\n",
    "\n",
    "step = forecast_days*samples_per_day\n",
    "\n",
    "input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_set_1 = datos[(datos['FECHAHORA']) < (datos.FECHAHORA.min() + relativedelta(months=3))]\n",
    "# print(train_set_1.info())\n",
    "# print(train_set_1.FECHAHORA.min())\n",
    "\n",
    "train_set_2 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=6))]\n",
    "# print(train_set_2.info())\n",
    "# print(train_set_2.FECHAHORA.min())\n",
    "\n",
    "train_set_3 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=9))]\n",
    "# print(train_set_3.FECHAHORA.min())\n",
    "\n",
    "train_set_4 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=12))]\n",
    "#print(train_set_4.FECHAHORA.min())\n",
    "\n",
    "train_set_5 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(years = 1, months = 3))]\n",
    "#print(train_set_5.FECHAHORA.min())\n",
    "\n",
    "test_set_1 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=6)))]\n",
    "\n",
    "test_set_2 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=9)))]\n",
    "\n",
    "test_set_3 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=12)))]\n",
    "\n",
    "test_set_4 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=15)))]\n",
    "\n",
    "test_set_5 = datos\n",
    "\n",
    "set_set = [[train_set_1, 2, test_set_1, 3], [train_set_2, 5, test_set_2, 6], [train_set_3, 8, test_set_3, 9], \n",
    "           [train_set_4, 11, test_set_4, 12], [train_set_5, 14, test_set_5, 15]]\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    train_months = relativedelta(months = set_set[i][1])\n",
    "    df_train = set_set[i][0]\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                        estacion,\n",
    "                                                        train_months, \n",
    "                                                        variables, \n",
    "                                                        dependent, \n",
    "                                                        train_test_samples, \n",
    "                                                        input_samples, \n",
    "                                                        output_samples, \n",
    "                                                        number_of_features,\n",
    "                                                        step)\n",
    "    \n",
    "    params = {'max_depth': 5,\n",
    "              'learning_rate': 0.028118418737147,\n",
    "              'n_estimators': 174,\n",
    "              'min_child_weight': 6,\n",
    "              'gamma':  0.00392389768210,\n",
    "              'subsample': 0.383249592275572,\n",
    "              'colsample_bytree': 0.760216507183716}\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    # validation\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    mape_val = mean_absolute_percentage_error(prediction, y_test)\n",
    "    mae_val = mean_absolute_error(prediction, y_test)\n",
    "    rmse_val = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    print('val MAPE, MAE, RMSE:')\n",
    "\n",
    "    print(mape_val)\n",
    "    print(mae_val)\n",
    "    print(rmse_val)\n",
    "\n",
    "    mape.append(mape_val)\n",
    "    mae.append(mae_val)\n",
    "    rmse.append(rmse_val)\n",
    "\n",
    "    # testing\n",
    "    \n",
    "    train_months = relativedelta(months = set_set[i][3])\n",
    "    df_train = set_set[i][2]\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                        estacion,\n",
    "                                                        train_months, \n",
    "                                                        variables, \n",
    "                                                        dependent, \n",
    "                                                        train_test_samples, \n",
    "                                                        input_samples, \n",
    "                                                        output_samples, \n",
    "                                                        number_of_features,\n",
    "                                                        step)\n",
    "    \n",
    "    # # params = {'max_depth': 5,\n",
    "    #           'learning_rate': 0.024093830590526,\n",
    "    #           'n_estimators': 224,\n",
    "    #           'min_child_weight': 6,\n",
    "    #           'gamma':  0.005342041600216,\n",
    "    #           'subsample': 0.635588411140476,\n",
    "    #           'colsample_bytree': 0.998857049787802}\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    mape_test = mean_absolute_percentage_error(prediction, y_test)\n",
    "    mae_test = mean_absolute_error(prediction, y_test)\n",
    "    rmse_test = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    print('----')\n",
    "    print('test MAPE, MAE, RMSE:')\n",
    "\n",
    "    print(mape_test)\n",
    "    print(mae_test)\n",
    "    print(rmse_test)\n",
    "\n",
    "    print('----')\n",
    "\n",
    "    mape_t.append(mape_test)\n",
    "    mae_t.append(mae_test)\n",
    "    rmse_t.append(rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "0.15826123085023253\n",
      "4.2193173483276585\n",
      "5.849074223147202\n",
      "test\n",
      "0.15768708564113507\n",
      "4.374786467421414\n",
      "6.72225937483198\n"
     ]
    }
   ],
   "source": [
    "print('val')\n",
    "print(sum(mape)/5)\n",
    "print(sum(mae)/5)\n",
    "print(sum(rmse)/5)\n",
    "\n",
    "print('test')\n",
    "print(sum(mape_t)/5)\n",
    "print(sum(mae_t)/5)\n",
    "print(sum(rmse_t)/5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24 horas / validation + testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val MAPE, MAE, RMSE:\n",
      "0.3140261346199862\n",
      "10.135150297188465\n",
      "13.480858792694411\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.2385204276676803\n",
      "9.098171531037892\n",
      "11.59673231950279\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.16575850830129643\n",
      "6.278678655133817\n",
      "7.581406095315518\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.26466867739238603\n",
      "7.549707416068301\n",
      "13.743613679004902\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.22441637711488446\n",
      "4.318481242136349\n",
      "5.231903136722768\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.2328102028719783\n",
      "6.171935854460855\n",
      "7.649998696501136\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.18218692155716162\n",
      "5.6047066528172715\n",
      "8.256284060961145\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.29701221612473605\n",
      "6.98545778403529\n",
      "9.027430034087201\n",
      "----\n",
      "val MAPE, MAE, RMSE:\n",
      "0.3412092450150182\n",
      "6.684620620291909\n",
      "8.083185552467983\n",
      "----\n",
      "test MAPE, MAE, RMSE:\n",
      "0.2684986239616797\n",
      "8.039213509802465\n",
      "10.740971985377206\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "estacion = 4\n",
    "\n",
    "mape = []\n",
    "rmse = []\n",
    "mae = []\n",
    "\n",
    "mape_t = []\n",
    "rmse_t = []\n",
    "mae_t = []\n",
    "\n",
    "\n",
    "# resampling\n",
    "\n",
    "datos.drop(['ANHO', 'DIA', 'MES', 'HORA', 'MINUTO', 'DIA_TRAF_COD', 'TRAFICO_COD', 'TIPO_COD',\n",
    "                'MEDICION_DIA', 'MP1_ANTERIOR', 'MP2_5_ANTERIOR', 'MP10_ANTERIOR',\n",
    "                'TEMPERATURA_PRONOSTICO', 'HUMEDAD_PRONOSTICO', 'PRESION_PRONOSTICO'], axis = 1, inplace = True)\n",
    "\n",
    "datos = datos.set_index('FECHAHORA', drop = True)\n",
    "\n",
    "r_i = '30T'\n",
    "lista_resample = []\n",
    "\n",
    "for station in range(1,11):\n",
    "    df_aux = datos[datos['ESTACION'] == station]\n",
    "\n",
    "    df_aux = df_aux.resample(r_i).mean()\n",
    "    lista_resample.append(df_aux)\n",
    "\n",
    "datos = pd.concat(lista_resample)\n",
    "\n",
    "datos['ANHO'] = datos.index.year\n",
    "datos['MES'] = datos.index.month\n",
    "datos['DIA'] = datos.index.day\n",
    "datos['HORA'] = datos.index.hour\n",
    "datos['MINUTO'] = datos.index.minute\n",
    "datos['FECHAHORA'] = datos.index\n",
    "datos.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "variables = [\"ANHO\", 'DIA', 'MES', 'HORA', 'MINUTO', 'MP1', 'MP2_5', 'MP10', 'AQI_MP10', 'AQI_MP2_5', 'TIPO', 'TRAFICO', 'HUMEDAD', \n",
    "                        'PRESION', 'TEMPERATURA','DIA_SEM']\n",
    "dependent = ['AQI_MP2_5']\n",
    "\n",
    "number_of_features = len(variables)\n",
    "\n",
    "forecast_days = 1\n",
    "training_days = 2\n",
    "samples_per_day = 48\n",
    "\n",
    "step = forecast_days*samples_per_day\n",
    "\n",
    "input_samples = int(samples_per_day * training_days) # cantidad de muestras en 7 dias\n",
    "output_samples = int(samples_per_day * forecast_days) # cantidad de muestras en 1 dia\n",
    "train_test_samples = int(input_samples + output_samples) # cantidad de datos para el train_test\n",
    "\n",
    "\n",
    "train_set_1 = datos[(datos['FECHAHORA']) < (datos.FECHAHORA.min() + relativedelta(months=3))]\n",
    "# print(train_set_1.info())\n",
    "# print(train_set_1.FECHAHORA.min())\n",
    "\n",
    "train_set_2 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=6))]\n",
    "# print(train_set_2.info())\n",
    "# print(train_set_2.FECHAHORA.min())\n",
    "\n",
    "train_set_3 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=9))]\n",
    "# print(train_set_3.FECHAHORA.min())\n",
    "\n",
    "train_set_4 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=12))]\n",
    "#print(train_set_4.FECHAHORA.min())\n",
    "\n",
    "train_set_5 = datos[datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(years = 1, months = 3))]\n",
    "#print(train_set_5.FECHAHORA.min())\n",
    "\n",
    "test_set_1 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=6)))]\n",
    "\n",
    "test_set_2 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=9)))]\n",
    "\n",
    "test_set_3 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=12)))]\n",
    "\n",
    "test_set_4 = datos[(datos['FECHAHORA'] < (datos.FECHAHORA.min() + relativedelta(months=15)))]\n",
    "\n",
    "test_set_5 = datos\n",
    "\n",
    "set_set = [[train_set_1, 2, test_set_1, 3], [train_set_2, 5, test_set_2, 6], [train_set_3, 8, test_set_3, 9], \n",
    "           [train_set_4, 11, test_set_4, 12], [train_set_5, 14, test_set_5, 15]]\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    train_months = relativedelta(months = set_set[i][1])\n",
    "    df_train = set_set[i][0]\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                        estacion,\n",
    "                                                        train_months, \n",
    "                                                        variables, \n",
    "                                                        dependent, \n",
    "                                                        train_test_samples, \n",
    "                                                        input_samples, \n",
    "                                                        output_samples, \n",
    "                                                        number_of_features,\n",
    "                                                        step)\n",
    "    \n",
    "    params = {'max_depth': 5,\n",
    "              'learning_rate': 0.028118418737147,\n",
    "              'n_estimators': 174,\n",
    "              'min_child_weight': 6,\n",
    "              'gamma':  0.00392389768210,\n",
    "              'subsample': 0.383249592275572,\n",
    "              'colsample_bytree': 0.760216507183716}\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    # validation\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    mape_val = mean_absolute_percentage_error(prediction, y_test)\n",
    "    mae_val = mean_absolute_error(prediction, y_test)\n",
    "    rmse_val = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    print('val MAPE, MAE, RMSE:')\n",
    "\n",
    "    print(mape_val)\n",
    "    print(mae_val)\n",
    "    print(rmse_val)\n",
    "\n",
    "    mape.append(mape_val)\n",
    "    mae.append(mae_val)\n",
    "    rmse.append(rmse_val)\n",
    "\n",
    "    # testing\n",
    "    \n",
    "    train_months = relativedelta(months = set_set[i][3])\n",
    "    df_train = set_set[i][2]\n",
    "\n",
    "    X_train, y_train, X_test, y_test = utils_xgboost.get_everything(df_train, \n",
    "                                                        estacion,\n",
    "                                                        train_months, \n",
    "                                                        variables, \n",
    "                                                        dependent, \n",
    "                                                        train_test_samples, \n",
    "                                                        input_samples, \n",
    "                                                        output_samples, \n",
    "                                                        number_of_features,\n",
    "                                                        step)\n",
    "    \n",
    "    # # params = {'max_depth': 5,\n",
    "    #           'learning_rate': 0.024093830590526,\n",
    "    #           'n_estimators': 224,\n",
    "    #           'min_child_weight': 6,\n",
    "    #           'gamma':  0.005342041600216,\n",
    "    #           'subsample': 0.635588411140476,\n",
    "    #           'colsample_bytree': 0.998857049787802}\n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(** params)\n",
    "\n",
    "    trained_xgb_model = MultiOutputRegressor(xgb_model).fit(X_train , y_train)\n",
    "\n",
    "    prediction = trained_xgb_model.predict(X_test)\n",
    "\n",
    "    mape_test = mean_absolute_percentage_error(prediction, y_test)\n",
    "    mae_test = mean_absolute_error(prediction, y_test)\n",
    "    rmse_test = mean_squared_error(prediction, y_test, squared = False)\n",
    "\n",
    "    print('----')\n",
    "    print('test MAPE, MAE, RMSE:')\n",
    "\n",
    "    print(mape_test)\n",
    "    print(mae_test)\n",
    "    print(rmse_test)\n",
    "\n",
    "    print('----')\n",
    "\n",
    "    mape_t.append(mape_test)\n",
    "    mae_t.append(mae_test)\n",
    "    rmse_t.append(rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "0.24551943732166942\n",
      "6.604327493513563\n",
      "8.526727527632364\n",
      "test\n",
      "0.2603020296036921\n",
      "7.568897219080961\n",
      "10.551749342894649\n"
     ]
    }
   ],
   "source": [
    "print('val')\n",
    "print(sum(mape)/5)\n",
    "print(sum(mae)/5)\n",
    "print(sum(rmse)/5)\n",
    "\n",
    "print('test')\n",
    "print(sum(mape_t)/5)\n",
    "print(sum(mae_t)/5)\n",
    "print(sum(rmse_t)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02308301664139756\n",
      "0.9851038738809955\n",
      "2.100452272202814\n"
     ]
    }
   ],
   "source": [
    "print(np.std(mape_t))\n",
    "print(np.std(mae_t))\n",
    "print(np.std(rmse_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015289969718474948\n",
      "0.39702574597469936\n",
      "1.6316919400006857\n"
     ]
    }
   ],
   "source": [
    "mape_6h_t = [0.08419537646581533, 0.12512136579509944, 0.09328873509342106, 0.1106172285783314, 0.08855821508274514]\n",
    "\n",
    "mae_6h_t = [3.028277209726733, 3.0658148950705475, 2.050405872558391, 2.307482436602478, 2.581419974087197]\n",
    "\n",
    "rmse_6h_t = [4.13499972885405, 7.532418206983646, 2.949560705283904, 3.4348947234257383,3.76658622549937 ]\n",
    "\n",
    "print(np.std(mape_6h_t))\n",
    "print(np.std(mae_6h_t))\n",
    "print(np.std(rmse_6h_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01805997977513935\n",
      "0.7713349103807424\n",
      "1.9275019725328022\n"
     ]
    }
   ],
   "source": [
    "mape_12h_t = [0.1421206813974915, 0.1867957973361338, 0.14448701349456702, 0.17106004127923666, 0.14397189469824634]\n",
    "\n",
    "mae_12h_t = [5.419319690827773,4.993113176819702, 3.496045252903407, 3.5234870070080597, 4.4419672095481255]\n",
    "\n",
    "rmse_12h_t = [7.022219811727332,10.233168993040133, 5.071356564982491, 4.900100799176308, 6.384450705233636]\n",
    "\n",
    "print(np.std(mape_12h_t))\n",
    "print(np.std(mae_12h_t))\n",
    "print(np.std(rmse_12h_t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
